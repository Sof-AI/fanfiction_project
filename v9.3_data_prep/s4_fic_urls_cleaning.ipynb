{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2e90ba",
   "metadata": {},
   "source": [
    "# Cleaning s4 fic_urls for merging with s4 fic_text\n",
    "## Also, cleaning s4 series text -> s5 series text\n",
    "- **By:** Sofia Kobayashi\n",
    "- **Date:** 11/02/2023\n",
    "- **Description:** Need to add fic_id, author, title, fandoms, and location to s4 fic_urls since that is what are used in fic matching comparisons\n",
    "    - Broke fic_urls into 3 DFs: ao3, ffn, oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9b649fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import AO3\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "env_path = Path(\".\") / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "762fc1b6-5f14-48e4-8aff-95ed7fc5bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "LOCATION_ORDER = {'ao3': 1,\n",
    "                  'ffn_net': 2,\n",
    "                  'tum': 3,\n",
    "                  'drm': 4,\n",
    "                  'lvj': 5,\n",
    "                  'fcb': 6,\n",
    "                  'wat': 7,\n",
    "                  'pdf': 9,\n",
    "                  'oth': 100,\n",
    "                 }\n",
    "\n",
    "DTB_ORDER = {'coffee': 1,\n",
    "            'read': 2,\n",
    "            'cont_read': 3,\n",
    "            'to_read': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09875b1",
   "metadata": {},
   "source": [
    "## Load in s4 fic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e72dfc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version_num</th>\n",
       "      <th>smk_source</th>\n",
       "      <th>dtb_type</th>\n",
       "      <th>location</th>\n",
       "      <th>fic_id</th>\n",
       "      <th>url</th>\n",
       "      <th>categories</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>fandom_type</th>\n",
       "      <th>fandom</th>\n",
       "      <th>fic_status</th>\n",
       "      <th>title</th>\n",
       "      <th>is_coffee</th>\n",
       "      <th>fic_series</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>is_subbed</th>\n",
       "      <th>is_backedup</th>\n",
       "      <th>is_bookmarked</th>\n",
       "      <th>in_category</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>current_chapter</th>\n",
       "      <th>fic_rating</th>\n",
       "      <th>to_read_rating</th>\n",
       "      <th>to_read_description</th>\n",
       "      <th>is_finished_inputting_data</th>\n",
       "      <th>ffn_date_updated_2-4-23</th>\n",
       "      <th>ffn_date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>7.0</td>\n",
       "      <td>v7_updates</td>\n",
       "      <td>to_read</td>\n",
       "      <td>ao3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://archiveofourown.org/works/260273/chapte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>batman,dcu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gonna Be A Better One (A Thousand Miles To You...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TimKon, In which Tim quits being Robin, Kon re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ao3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.archiveofourown.org/works/26671084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ao3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.archiveofourown.org/works/27740392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ao3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.archiveofourown.org/works/31373576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>7.1</td>\n",
       "      <td>v7.1_ffn</td>\n",
       "      <td>read</td>\n",
       "      <td>ao3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://archiveofourown.org/works/717740/chapt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bleach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On Life, On Death, On Everything In-Between</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cywscross,</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>well_written,.Time Travel,.BAMF,.Fix-It,.Prote...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      version_num      smk_source dtb_type location  fic_id  \\\n",
       "579           7.0      v7_updates  to_read      ao3     NaN   \n",
       "1589          8.0  v8_local_files      NaN      ao3     NaN   \n",
       "1590          8.0  v8_local_files      NaN      ao3     NaN   \n",
       "1591          8.0  v8_local_files      NaN      ao3     NaN   \n",
       "960           7.1        v7.1_ffn     read      ao3     NaN   \n",
       "\n",
       "                                                    url categories is_bold  \\\n",
       "579   http://archiveofourown.org/works/260273/chapte...        NaN   False   \n",
       "1589      http://www.archiveofourown.org/works/26671084        NaN     NaN   \n",
       "1590      http://www.archiveofourown.org/works/27740392        NaN     NaN   \n",
       "1591      http://www.archiveofourown.org/works/31373576        NaN     NaN   \n",
       "960   https://archiveofourown.org/works/717740/chapt...        NaN     NaN   \n",
       "\n",
       "      fandom_type      fandom  fic_status  \\\n",
       "579           NaN  batman,dcu         NaN   \n",
       "1589          NaN         NaN         NaN   \n",
       "1590          NaN         NaN         NaN   \n",
       "1591          NaN         NaN         NaN   \n",
       "960           NaN      bleach         NaN   \n",
       "\n",
       "                                                  title is_coffee fic_series  \\\n",
       "579   Gonna Be A Better One (A Thousand Miles To You...       NaN        NaN   \n",
       "1589                                                NaN       NaN        NaN   \n",
       "1590                                                NaN       NaN        NaN   \n",
       "1591                                                NaN       NaN        NaN   \n",
       "960         On Life, On Death, On Everything In-Between       NaN        NaN   \n",
       "\n",
       "          author length is_complete is_subbed is_backedup  is_bookmarked  \\\n",
       "579          NaN    NaN         NaN       NaN         NaN            NaN   \n",
       "1589         NaN    NaN         NaN       NaN         NaN            NaN   \n",
       "1590         NaN    NaN         NaN       NaN         NaN            NaN   \n",
       "1591         NaN    NaN         NaN       NaN         NaN            NaN   \n",
       "960   cywscross,     51       False      True        TRUE            NaN   \n",
       "\n",
       "      in_category                                           all_tags  \\\n",
       "579           NaN                                                NaN   \n",
       "1589          NaN                                                NaN   \n",
       "1590          NaN                                                NaN   \n",
       "1591          NaN                                                NaN   \n",
       "960           NaN  well_written,.Time Travel,.BAMF,.Fix-It,.Prote...   \n",
       "\n",
       "     current_chapter  fic_rating to_read_rating  \\\n",
       "579              NaN         NaN            NaN   \n",
       "1589             NaN         NaN            NaN   \n",
       "1590             NaN         NaN            NaN   \n",
       "1591             NaN         NaN            NaN   \n",
       "960              NaN         3.0            NaN   \n",
       "\n",
       "                                    to_read_description  \\\n",
       "579   TimKon, In which Tim quits being Robin, Kon re...   \n",
       "1589                                                NaN   \n",
       "1590                                                NaN   \n",
       "1591                                                NaN   \n",
       "960                                                 NaN   \n",
       "\n",
       "     is_finished_inputting_data ffn_date_updated_2-4-23 ffn_date_added  \n",
       "579                         NaN                     NaN            NaN  \n",
       "1589                        NaN                     NaN            NaN  \n",
       "1590                        NaN                     NaN            NaN  \n",
       "1591                        NaN                     NaN            NaN  \n",
       "960                        True                     NaN            NaN  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_data_4/all_versions_fic_url.csv', index_col=0, encoding='utf-8-sig')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "94045217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF LEN: 3834 \n",
      "\n",
      "fic_id 3667\n",
      "title 2278\n",
      "author 2609\n",
      "location 0\n",
      "fandom 2413\n"
     ]
    }
   ],
   "source": [
    "# REPORT: fic_id, title, author, location, fandom\n",
    "print(\"DF LEN:\", len(df), \"\\n\")\n",
    "for col in ['fic_id','title','author','location','fandom']:\n",
    "    print(col, len(df[pd.isnull(df[col])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "19d400df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3834, 3834)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the 3 url types\n",
    "df = pd.read_csv('clean_data_4/all_versions_fic_url.csv', index_col=0, encoding='utf-8')\n",
    "\n",
    "ao3_urls = [url for url in df.url.to_list() if 'archiveofourown.org' in url]\n",
    "ffn_urls = [url for url in df.url.to_list() if 'fanfiction.net' in url]\n",
    "oth_urls = [url for url in df.url.to_list() if 'archiveofourown.org' not in url \n",
    "            and 'fanfiction.net' not in url]\n",
    "\n",
    "# Making 3 df types\n",
    "ao3 = df[df.url.isin(ao3_urls)]\n",
    "ffn = df[df.url.isin(ffn_urls)]\n",
    "oth = df[df.url.isin(oth_urls)]\n",
    "\n",
    "len(ao3_urls) + len(ffn_urls) + len(oth_urls), len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e7674",
   "metadata": {},
   "source": [
    "## AO3 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38958d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# fic_id is null: 0'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill fic_id\n",
    "for ind in ao3.index:\n",
    "    fic_id = re.compile(r'/works/(\\d+)').findall(ao3.loc[ind].url)\n",
    "    ao3.loc[ind, 'fic_id'] = fic_id[0] if fic_id else ao3.loc[ind, 'fic_id']\n",
    "    \n",
    "\"# fic_id is null: \" + str(len(ao3[pd.isnull(ao3.fic_id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9fa2de09-664d-4d4d-86de-e9ebe1d12210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ao3'], dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ao3.location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ad2136b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# blank titles: ', 58)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in cleaned CSV (not sure where it's from)\n",
    "ao3 = pd.read_csv('clean_data_4/all_versions_fic_url_clean_ao3.csv', encoding='utf-8-sig', index_col=0)\n",
    "\n",
    "\"# blank titles: \", len(ao3[pd.isnull(ao3.title)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10cdbe-16a8-4345-918f-1496fe1ca2b9",
   "metadata": {},
   "source": [
    "## Merge fics in s4 fic urls\n",
    "- **Problem:** there are many rows with the SAME fic_id\n",
    "- **Thus:** will merge all rows w/ same id -> one row\n",
    "- **Desired Result:** DF where there are only one row per fic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af154810-e8f6-4d0a-ad3b-465fc020f732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Helpers for merge_in_id()\n",
    "def stringify_dict(dict):\n",
    "    \"\"\"\n",
    "    Takes dict.\n",
    "    Stringifies any keys that are lists (so can be stored in pd.DataFrame).\n",
    "    Returns dict.\n",
    "    \"\"\"\n",
    "    for key in dict:\n",
    "        # if isinstance(dict[key], list):\n",
    "        dict[key] = json.dumps(dict[key], ensure_ascii=False) # Don't encode non-ascii characters\n",
    "    return dict\n",
    "\n",
    "# Testing stringify_lists_in_dict()\n",
    "# stringify_dict(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0d78c8-6761-4bb8-bcb4-fdb8beade96b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ao3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# return stringify_dict(result)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Testing merge_on_id()\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m t1 \u001b[38;5;241m=\u001b[39m merge_on_id(\u001b[43mao3\u001b[49m, \u001b[38;5;241m46592134\u001b[39m)\n\u001b[1;32m     78\u001b[0m t1\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ao3' is not defined"
     ]
    }
   ],
   "source": [
    "# Merge on fic_id function\n",
    "def merge_on_id(parent_df, fic_id) -> dict:\n",
    "    \"\"\"\n",
    "    Takes a coffee df (df), either text or url, ideally of multiple rows.\n",
    "    Merges data, as specificed below, into a single row.\n",
    "    Returns author dict of merged info (dict).\n",
    "    \"\"\"\n",
    "    # Load in df of fics with given fic_id\n",
    "    df = parent_df[parent_df['fic_id'] == fic_id]\n",
    "\n",
    "    # Make sure there are NOT empty dfs\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: len 0\")\n",
    "        return {}     \n",
    "\n",
    "    # Get dict, remove NaN's & de-dup lists\n",
    "    cols = df.to_dict('list')\n",
    "    for key in cols:\n",
    "        cols[key] = list(set([ele for ele in cols[key] if not pd.isna(ele)]))\n",
    "\n",
    "    # Sort & clean various attributes\n",
    "    sorted_sources = sorted(cols['smk_source'], key = lambda source: float(source.split('_')[0][1:]))\n",
    "    clean_authors = [author.replace(\",\", \"\") for author in cols['author']]\n",
    "\n",
    "    clean_dtbs = set()\n",
    "    for dtb_str in cols['dtb_type']:\n",
    "        new_dtbs = dtb_str.split(',')\n",
    "        for dtb in new_dtbs:\n",
    "            clean_dtbs.add(dtb.strip())\n",
    "    clean_dtbs = list(clean_dtbs)\n",
    "    sorted_dtbs = sorted(clean_dtbs, key=lambda dtb: DTB_ORDER[dtb])\n",
    "    avg_rating = None if len(cols['fic_rating']) == 0 else round(sum(cols['fic_rating'])/len(cols['fic_rating']), 2)\n",
    "\n",
    "    # Make sure there are all cols from s4 fic urls AND all cols from s5 stuff\n",
    "    result = {'primary_version': min(cols['version_num']), \n",
    "            'version_nums': cols['version_num'],\n",
    "            'primary_source': [] if len(sorted_sources) == 1 else sorted_sources[0],\n",
    "            'smk_sources': sorted_sources, \n",
    "            'primary_location': 'ao3', # they're all from ao3 \n",
    "            'locations': cols['location'],\n",
    "            'work_type': 'fic', # they're all fics \n",
    "            'fandom': cols['fandom'],\n",
    "            'title': \"\" if len(cols['title']) ==0 else cols['title'][0], \n",
    "            'author': clean_authors, \n",
    "            'primary_link': 'https://archiveofourown.org/works/'+str(int(fic_id)), \n",
    "            'all_links' : cols['url'],\n",
    "            'fic_id': int(fic_id),\n",
    "            'num_appeared': len(df),\n",
    "            'primary_dtb': \"\" if len(sorted_dtbs) == 0 else sorted_dtbs[0],\n",
    "            'dtb_types': sorted_dtbs,\n",
    "            'fic_series': cols['fic_series'],\n",
    "            'is_bold': cols['is_bold'],\n",
    "            'is_coffee': cols['is_coffee'],\n",
    "            'is_complete': cols['is_complete'],\n",
    "            'is_subbed': cols['is_subbed'],\n",
    "            'is_bookmarked': cols['is_bookmarked'],\n",
    "            'is_finished_inputting_data': cols['is_finished_inputting_data'],\n",
    "            'is_backedup': cols['is_backedup'],\n",
    "            'categories': cols['categories'],\n",
    "            'current_chapter': cols['current_chapter'],\n",
    "            'all_tags': cols['all_tags'],\n",
    "            'fic_rating': avg_rating,\n",
    "            'all_ratings': cols['fic_rating'],\n",
    "            'fandom_type': cols['fandom_type'],\n",
    "            'ffn_date_added': cols['ffn_date_added'],\n",
    "            'ffn_date_updated_2-4-23': cols['ffn_date_updated_2-4-23'],\n",
    "            'fic_status': cols['fic_status'],\n",
    "            'in_category': cols['in_category'],\n",
    "            'readability_status': cols['readability_status'],\n",
    "            'to_read_description': cols['to_read_description'],\n",
    "            'to_read_rating': cols['to_read_rating'],\n",
    "           }\n",
    "    return result\n",
    "    # return stringify_dict(result)\n",
    "\n",
    "# Testing merge_on_id()\n",
    "t1 = merge_on_id(ao3, 46592134)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c96fe8cb-104f-4800-b255-abf62b80ac59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing for specific ids\n",
    "cols = ao3[ao3['fic_id'] == 46592134].to_dict('list')\n",
    "for key in cols:\n",
    "    cols[key] = list(set([ele for ele in cols[key] if not pd.isna(ele)]))\n",
    "# cols  \n",
    "\n",
    "# # Print sorting keys NOT already in merge_on_id() output\n",
    "# sorted_keys = sorted(cols.keys())\n",
    "# for key in sorted_keys:\n",
    "#     if key not in t1:\n",
    "#         print(f\"{key}: {cols[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a873812-7364-455e-bf20-5cb9df34a949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_version</th>\n",
       "      <th>version_nums</th>\n",
       "      <th>primary_source</th>\n",
       "      <th>smk_sources</th>\n",
       "      <th>primary_location</th>\n",
       "      <th>locations</th>\n",
       "      <th>work_type</th>\n",
       "      <th>fandom</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>primary_link</th>\n",
       "      <th>all_links</th>\n",
       "      <th>fic_id</th>\n",
       "      <th>num_appeared</th>\n",
       "      <th>primary_dtb</th>\n",
       "      <th>dtb_types</th>\n",
       "      <th>fic_series</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>is_coffee</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>is_subbed</th>\n",
       "      <th>is_bookmarked</th>\n",
       "      <th>is_finished_inputting_data</th>\n",
       "      <th>is_backedup</th>\n",
       "      <th>categories</th>\n",
       "      <th>current_chapter</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>fic_rating</th>\n",
       "      <th>all_ratings</th>\n",
       "      <th>fandom_type</th>\n",
       "      <th>ffn_date_added</th>\n",
       "      <th>ffn_date_updated_2-4-23</th>\n",
       "      <th>fic_status</th>\n",
       "      <th>in_category</th>\n",
       "      <th>readability_status</th>\n",
       "      <th>to_read_description</th>\n",
       "      <th>to_read_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[7.1, 7.0]</td>\n",
       "      <td>v7_ffn</td>\n",
       "      <td>[v7_ffn, v7.1_ffn]</td>\n",
       "      <td>ao3</td>\n",
       "      <td>[ao3]</td>\n",
       "      <td>fic</td>\n",
       "      <td>[fullmental_alchemist]</td>\n",
       "      <td>Window Dressing</td>\n",
       "      <td>[thehoyden]</td>\n",
       "      <td>https://archiveofourown.org/works/46181</td>\n",
       "      <td>[https://archiveofourown.org/works/46181]</td>\n",
       "      <td>46181</td>\n",
       "      <td>2</td>\n",
       "      <td>read</td>\n",
       "      <td>[read]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[FALSE]</td>\n",
       "      <td>[favorite,smile]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[well_written,.Relationship,.Fluff,.Cute, .Rel...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[readable]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[7.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[v7_toread]</td>\n",
       "      <td>ao3</td>\n",
       "      <td>[ao3]</td>\n",
       "      <td>fic</td>\n",
       "      <td>[naruto]</td>\n",
       "      <td>How to File Form 39-B</td>\n",
       "      <td>[thehoyden]</td>\n",
       "      <td>https://archiveofourown.org/works/46222</td>\n",
       "      <td>[https://archiveofourown.org/works/46222]</td>\n",
       "      <td>46222</td>\n",
       "      <td>1</td>\n",
       "      <td>to_read</td>\n",
       "      <td>[to_read]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[readable]</td>\n",
       "      <td>[Iruka/Kakashi meet cute, smut, sweet dreams]</td>\n",
       "      <td>[sd]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[7.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[v7_toread]</td>\n",
       "      <td>ao3</td>\n",
       "      <td>[ao3]</td>\n",
       "      <td>fic</td>\n",
       "      <td>[naruto]</td>\n",
       "      <td>Telephone</td>\n",
       "      <td>[rageprufrock]</td>\n",
       "      <td>https://archiveofourown.org/works/48095</td>\n",
       "      <td>[https://archiveofourown.org/works/48095]</td>\n",
       "      <td>48095</td>\n",
       "      <td>1</td>\n",
       "      <td>to_read</td>\n",
       "      <td>[to_read]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[-]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[readable]</td>\n",
       "      <td>[sounds good]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>[8.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[v8_local_files]</td>\n",
       "      <td>ao3</td>\n",
       "      <td>[ao3]</td>\n",
       "      <td>fic</td>\n",
       "      <td>[Leverage,Batman (Movies - Nolan)]</td>\n",
       "      <td>Five times the Leverage Crew was not in Gotham...</td>\n",
       "      <td>[noelia_g]</td>\n",
       "      <td>https://archiveofourown.org/works/76861</td>\n",
       "      <td>[https://archiveofourown.org/works/76861]</td>\n",
       "      <td>76861</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[readable]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>[8.0, 7.0]</td>\n",
       "      <td>v7_updates</td>\n",
       "      <td>[v7_updates, v8_local_files]</td>\n",
       "      <td>ao3</td>\n",
       "      <td>[ao3]</td>\n",
       "      <td>fic</td>\n",
       "      <td>[Chronicles of Narnia - C. S. Lewis]</td>\n",
       "      <td>Carpetbaggers</td>\n",
       "      <td>[cofax]</td>\n",
       "      <td>https://archiveofourown.org/works/106190</td>\n",
       "      <td>[https://archiveofourown.org/works/106190, htt...</td>\n",
       "      <td>106190</td>\n",
       "      <td>3</td>\n",
       "      <td>cont_read</td>\n",
       "      <td>[cont_read]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[False]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[readable]</td>\n",
       "      <td>[ch 6, Narnia worldbuilding]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   primary_version version_nums primary_source                   smk_sources  \\\n",
       "0              7.0   [7.1, 7.0]         v7_ffn            [v7_ffn, v7.1_ffn]   \n",
       "1              7.0        [7.0]             []                   [v7_toread]   \n",
       "2              7.0        [7.0]             []                   [v7_toread]   \n",
       "3              8.0        [8.0]             []              [v8_local_files]   \n",
       "4              7.0   [8.0, 7.0]     v7_updates  [v7_updates, v8_local_files]   \n",
       "\n",
       "  primary_location locations work_type                                fandom  \\\n",
       "0              ao3     [ao3]       fic                [fullmental_alchemist]   \n",
       "1              ao3     [ao3]       fic                              [naruto]   \n",
       "2              ao3     [ao3]       fic                              [naruto]   \n",
       "3              ao3     [ao3]       fic    [Leverage,Batman (Movies - Nolan)]   \n",
       "4              ao3     [ao3]       fic  [Chronicles of Narnia - C. S. Lewis]   \n",
       "\n",
       "                                               title          author  \\\n",
       "0                                    Window Dressing     [thehoyden]   \n",
       "1                              How to File Form 39-B     [thehoyden]   \n",
       "2                                          Telephone  [rageprufrock]   \n",
       "3  Five times the Leverage Crew was not in Gotham...      [noelia_g]   \n",
       "4                                      Carpetbaggers         [cofax]   \n",
       "\n",
       "                               primary_link  \\\n",
       "0   https://archiveofourown.org/works/46181   \n",
       "1   https://archiveofourown.org/works/46222   \n",
       "2   https://archiveofourown.org/works/48095   \n",
       "3   https://archiveofourown.org/works/76861   \n",
       "4  https://archiveofourown.org/works/106190   \n",
       "\n",
       "                                           all_links  fic_id  num_appeared  \\\n",
       "0          [https://archiveofourown.org/works/46181]   46181             2   \n",
       "1          [https://archiveofourown.org/works/46222]   46222             1   \n",
       "2          [https://archiveofourown.org/works/48095]   48095             1   \n",
       "3          [https://archiveofourown.org/works/76861]   76861             1   \n",
       "4  [https://archiveofourown.org/works/106190, htt...  106190             3   \n",
       "\n",
       "  primary_dtb    dtb_types fic_series  is_bold is_coffee is_complete  \\\n",
       "0        read       [read]         []   [True]        []      [True]   \n",
       "1     to_read    [to_read]         []       []        []          []   \n",
       "2     to_read    [to_read]         []       []        []          []   \n",
       "3                       []         []       []        []          []   \n",
       "4   cont_read  [cont_read]         []  [False]        []          []   \n",
       "\n",
       "  is_subbed is_bookmarked is_finished_inputting_data is_backedup  \\\n",
       "0   [False]            []                     [True]     [FALSE]   \n",
       "1        []            []                     [True]          []   \n",
       "2        []            []                     [True]          []   \n",
       "3        []            []                         []          []   \n",
       "4        []            []                         []          []   \n",
       "\n",
       "         categories current_chapter  \\\n",
       "0  [favorite,smile]              []   \n",
       "1                []             [-]   \n",
       "2                []             [-]   \n",
       "3                []              []   \n",
       "4                []              []   \n",
       "\n",
       "                                            all_tags  fic_rating all_ratings  \\\n",
       "0  [well_written,.Relationship,.Fluff,.Cute, .Rel...         3.0       [3.0]   \n",
       "1                                                 []         NaN          []   \n",
       "2                                                 []         NaN          []   \n",
       "3                                                 []         NaN          []   \n",
       "4                                                 []         NaN          []   \n",
       "\n",
       "  fandom_type ffn_date_added ffn_date_updated_2-4-23 fic_status in_category  \\\n",
       "0          []             []                      []         []          []   \n",
       "1          []             []                      []         []          []   \n",
       "2          []             []                      []         []          []   \n",
       "3          []             []                      []         []          []   \n",
       "4          []             []                      []         []          []   \n",
       "\n",
       "  readability_status                            to_read_description  \\\n",
       "0         [readable]                                             []   \n",
       "1         [readable]  [Iruka/Kakashi meet cute, smut, sweet dreams]   \n",
       "2         [readable]                                  [sounds good]   \n",
       "3         [readable]                                             []   \n",
       "4         [readable]                   [ch 6, Narnia worldbuilding]   \n",
       "\n",
       "  to_read_rating  \n",
       "0             []  \n",
       "1           [sd]  \n",
       "2            [2]  \n",
       "3             []  \n",
       "4             []  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produces de-dupped df\n",
    "unique_fic_ids = ao3.fic_id.drop_duplicates().sort_values().to_list()\n",
    "merged_rows = []\n",
    "\n",
    "for i, id in enumerate(unique_fic_ids): \n",
    "    # print(f\"({i}/{len(unique_fic_ids)}) {id}\")\n",
    "    merged_row = merge_on_id(ao3, id)\n",
    "    merged_rows.append(merged_row)\n",
    "\n",
    "with open(\"clean_data_4/all_versions_fic_url_merged.json\", \"w\") as outfile:\n",
    "    json.dump(merged_rows, outfile)\n",
    "    \n",
    "ao3_2 = pd.DataFrame(merged_rows)\n",
    "ao3_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c71f64a3-cee0-47a8-9a1c-b634231803c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(total len, # of fic_ids)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2442, 2442)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that been de-dupped\n",
    "print(\"(total len, # of fic_ids)\")\n",
    "len(ao3_2.fic_id.to_list()), len(set(ao3_2.fic_id.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "436c23cf-bc4b-499f-9b0c-3db0e06147af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename, reorder cols, and sort DF\n",
    "ao3_2 = ao3_2[['fic_id', 'num_appeared', 'primary_version', 'title', 'author', 'fandom', 'version_nums', 'primary_source', \n",
    "       'smk_sources', 'primary_location', 'locations', 'work_type', 'primary_link', 'all_links', \n",
    "       'primary_dtb', 'dtb_types', 'fic_series', 'is_bold', 'is_coffee','is_complete', 'is_subbed', 'is_bookmarked',\n",
    "       'is_finished_inputting_data', 'is_backedup', 'categories', 'current_chapter', 'all_tags', 'fic_rating', 'all_ratings',\n",
    "       'fandom_type', 'ffn_date_added', 'ffn_date_updated_2-4-23','fic_status', 'in_category', 'readability_status', \n",
    "       'to_read_description', 'to_read_rating']]\n",
    "\n",
    "# Sort by fic_id\n",
    "ao3_2['fic_id'] = ao3_2['fic_id'].astype(int)\n",
    "ao3_2 = ao3_2.sort_values(by='fic_id').reset_index(drop=True)\n",
    "ao3_2['fic_id'] = ao3_2['fic_id'].astype(str)\n",
    "\n",
    "\n",
    "# Write to CSV\n",
    "ao3_2.to_csv(\"clean_data_4/all_versions_fic_url_merged_ao3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f83ee-87f2-4312-9081-960be3e20d5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fill s4 fic urls with info\n",
    "- **Problem:** many fics don't have all the info needed to match (ie. title, fandoms, authors, location)\n",
    "- **Thus:** will use AO3 API to retrieve & fill rows\n",
    "- **Desired Result:** DF with all rows having the info needed to compare fics (title, fandoms, authors, location)\n",
    "\n",
    "**Cols Needed to Compare Fics:** title, fandom, author, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6ac68b81-afa8-4d34-80c7-a7f81b09963f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in relevant files\n",
    "with open(\"clean_data_4/all_versions_fic_url_merged.json\", \"r\") as infile:\n",
    "    merged_dict = json.load(infile)\n",
    "    merged_dict.sort(key=lambda fic: int(fic['fic_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "33aeaa13-3252-4e0a-b12f-529106e5e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate AO3 Session\n",
    "ao3_session = AO3.Session(os.environ['AO3_USERNAME'], os.environ['AO3_PASSWORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "abfde5fc-1a30-4dd4-8881-7c1b97942146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill an AO3 fic\n",
    "def fill_all_fics(parent_dict, ao3_session):\n",
    "    error_count = 0\n",
    "    \n",
    "    for i, fic in enumerate(parent_dict):\n",
    "        # If essential info is empty AND no error present\n",
    "        if(fic['title'] == \"\" or fic['fandom'] == [] or fic['author'] == [] or fic['locations'] == []) and \"error\" not in fic: \n",
    "            \n",
    "            try: # Try to fill fic \n",
    "                work = AO3.Work(fic['fic_id'])\n",
    "                parent_dict[i]['title'] = work.title\n",
    "                parent_dict[i]['author'] = [author.username for author in work.authors]\n",
    "                parent_dict[i]['fandom'] = work.fandoms\n",
    "                parent_dict[i]['locations'] = ['ao3']\n",
    "                print(f'Filled {fic[\"fic_id\"]}')\n",
    "            except Exception as exception: # Add error if can't fill\n",
    "                errorName = type(exception).__name__\n",
    "                fic['error'] = type(exception).__name__\n",
    "                error_count += 1\n",
    "                print(f\"{errorName}: {fic['fic_id']}\")\n",
    "\n",
    "    print(f\"Done! {error_count} errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f1c0bdfa-c91a-4949-9e86-cbc6a6e20f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# Code to run fill all fics\n",
    "fill_all_fics(merged_dict, ao3_session)\n",
    "merged_dict[1651]['error'] = \"MyWeirdAttributeError\" # Giving AttributeError, but should be ok: https://archiveofourown.org/works/27688829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "332a4920-117a-4dc0-9053-6c77eb423ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all rows have (title, fandoms, author, locations) OR (error)\n",
    "for i, fic in enumerate(merged_dict):\n",
    "    if (fic['title'] == \"\" or fic['fandom'] == [] or fic['author'] == [] or fic['locations'] == []) and (\"error\" not in fic):\n",
    "        print(i, fic[\"title\"])\n",
    "\n",
    "# Printing nothing means it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e44fd802-ce73-49c2-9bdc-20f86ddc62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filled dict to JSON\n",
    "with open(\"clean_data_4/all_versions_fic_url_filled.json\", \"w\") as outfile:\n",
    "    json.dump(merged_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a6b56a5d-544b-42b6-b6a2-5ac91a15b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts(df, col_name):\n",
    "    \"\"\"\n",
    "    Helper function to show value_counts() AND values.\n",
    "    \"\"\"\n",
    "    counts = df[col_name].value_counts().to_list()\n",
    "    values = df[col_name].value_counts().index.to_list()\n",
    "\n",
    "    for i, val in enumerate(values):\n",
    "        print(f\"{counts[i]} {val}\")\n",
    "\n",
    "# show_counts(w, \"fandom\") # Will show some empty titles, fandoms, etc. -- it's the error fics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429bca2-4c4e-4efb-abc9-3b33e125dd17",
   "metadata": {},
   "source": [
    "**Added Errors**\n",
    "- InvalidIdError = 404 Not Found\n",
    "- AttributeError = Mystery Collection OR weird scraping error? should be working?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5adfa6-8554-4f98-b3a0-0d6b46a5c524",
   "metadata": {},
   "source": [
    "## Standardize fandoms\n",
    "- **Problem:** the fandoms in s4 fic url vs s4 fic text have what AO3 names fandoms vs what I called fandoms\n",
    "- **Thus:** I will match all of my fandom names -> AO3 fandom names & convert them to standardize fandoms\n",
    "- **Desired Result:** DF which rows' fandoms all draw from same AO3 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96774e10-e8f1-44f7-afcf-89d58013a574",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read in relevant files\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean_data_4/all_versions_fic_url_filled.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m----> 3\u001b[0m     non_standard_fandom_fics_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_info/fandom_aliases.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[1;32m      6\u001b[0m     FANDOM_NAMES \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in relevant files\n",
    "with open(\"clean_data_4/all_versions_fic_url_filled.json\", \"r\") as infile:\n",
    "    non_standard_fandom_fics_dict = json.load(infile)\n",
    "\n",
    "with open('reference_info/fandom_aliases.json', 'r') as infile:\n",
    "    FANDOM_NAMES = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ace63-f1ca-4b3e-ae64-44ae507ada57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned fic fandoms\n",
    "# Function to uncompact (split, dedup, order) fandom strings\n",
    "def split_and_sort_fandoms(dict):\n",
    "    for fic in dict:\n",
    "        clean_fandoms = set()\n",
    "        for fandom_str in fic['fandom']:\n",
    "            for fandom in fandom_str.split(\",\"):\n",
    "                if fandom != \"\":\n",
    "                    clean_fandoms.add(fandom.strip())\n",
    "                \n",
    "        fandom_list = list(clean_fandoms)\n",
    "        fic['fandom'] = sorted(fandom_list)\n",
    "\n",
    "# Clean dict\n",
    "split_and_sort_fandoms(non_standard_fandom_fics_dict)\n",
    "\n",
    "# Check for compacted fandoms\n",
    "for fic in non_standard_fandom_fics_dict:\n",
    "    for fandom_str in fic['fandom']:\n",
    "        if ',' in fandom_str:\n",
    "            print(fic['fandom'])\n",
    "\n",
    "# Printing none means it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "da1eaa60-d784-41c1-8d31-b174e658bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my fandoms -> AO3 fandoms dict\n",
    "FANDOM_CONVERSION = {    \n",
    "    '1/2_prince': '1/2 Wangzi | 1/2 Prince', \n",
    "    '2ha': \"二哈和他的白猫师尊 - 肉包不吃肉 | The Husky and His White Cat Shizun - Meatbun Doesn't Eat Meat\", \n",
    "    'assassins_creed': \"Assassin's Creed - All Media Types\", \n",
    "    'atla': 'Avatar: The Last Airbender', \n",
    "    'avengers': 'Avengers (Marvel) - All Media Types', \n",
    "    'batman': 'Batman - All Media Types', \n",
    "    'black_panther': 'Black Panther (2018)', \n",
    "    'bleach': 'Bleach', \n",
    "    'bnha': \"僕のヒーローアカデミア | Boku no Hero Academia | My Hero Academia\", \n",
    "    'bts': \"방탄소년단 | Bangtan Boys | BTS\", \n",
    "    'captain_america': 'Captain America - All Media Types', \n",
    "    'captive_prince': 'Captive Prince - C. S. Pacat', \n",
    "    'chronicles_of_narnia': 'Chronicles of Narnia - C. S. Lewis', \n",
    "    'code_geass': 'Code Geass', \n",
    "    'daredevil': 'Daredevil (TV)', \n",
    "    'dcu': 'DCU', \n",
    "    'descendants': \"Descendants (Disney Movies)\", \n",
    "    'detroit_become_human': 'Detroit: Become Human (Video Game)', \n",
    "    'fairy_tail': 'Fairy Tail', \n",
    "    'fbawtft': 'Fantastic Beasts and Where to Find Them (Movies)', \n",
    "    'final_fantasy_vii': 'Final Fantasy VII', \n",
    "    'final_fantasy_xv': 'Final Fantasy XV', \n",
    "    'folklore': 'Folklore', \n",
    "    'fullmetal_alchemist': 'Fullmetal Alchemist - All Media Types', \n",
    "    'game_of_thrones': 'A Song of Ice and Fire & Related Fandoms', \n",
    "    'good_omens': 'Good Omens (TV)', \n",
    "    'gotham': \"Gotham (TV)\", \n",
    "    'guardians_of_the_galaxy': 'Guardians of the Galaxy (Movies)', \n",
    "    'hamilton': 'Hamilton - Miranda', \n",
    "    'harry_potter': 'Harry Potter - Fandom', \n",
    "    'httyd': 'How to Train Your Dragon (Movies)', \n",
    "    'james_bond': 'James Bond (Movies)', \n",
    "    'john_wick': \"John Wick (Movies)\", \n",
    "    'joy_of_life': \"庆余年 | Joy of Life (TV)\", \n",
    "    'katekyo_hitman_reborn': 'Katekyou Hitman Reborn!', \n",
    "    'kingsman': 'Kingsman (Movies)', \n",
    "    'kuroko_no_basuke': \"Kuroko no Basuke | Kuroko's Basketball\", \n",
    "    'leverage': 'Leverage', \n",
    "    'lord_of_the_rings': \"The Lord of the Rings - All Media Types\", \n",
    "    'mcu': 'MCU', \n",
    "    'mdzs': '魔道祖师 - 墨香铜臭 | Módào Zǔshī - Mòxiāng Tóngxiù', \n",
    "    'megamind': 'Megamind (2010)', \n",
    "    'merlin': 'Merlin (TV)', \n",
    "    'minecraft': 'Minecraft (Video Game)', \n",
    "    'moon_knight': 'Moon Knight (TV 2022)', \n",
    "    'naruto': 'Naruto', \n",
    "    'one_piece': 'One Piece', \n",
    "    'percy_jackson_olympians': 'Percy Jackson and the Olympians & Related Fandoms - All Media Types', \n",
    "    'pkmn_sword&shield': 'Pocket Monsters: Sword & Shield | Pokemon Sword & Shield Versions', \n",
    "    'pokemon': 'Pocket Monsters | Pokemon (Anime)', \n",
    "    'rise_of_the_guardians': \"Rise of the Guardians (2012)\", \n",
    "    'rwby': \"RWBY\", \n",
    "    'sherlock': \"Sherlock (TV)\", \n",
    "    'spiderman': \"Spider-Man - All Media Types\", \n",
    "    'star_wars': \"Star Wars - All Media Types\", \n",
    "    'star_wars_cw': \"Star Wars: Clone Wars (2003) - All Media Types\", \n",
    "    'supernatural': \"Supernatural\", \n",
    "    'sword_art_online': \"Sword Art Online (Anime & Manga)\", \n",
    "    'teen_wolf': \"Teen Wolf (TV)\", \n",
    "    'the_arrow': \"Arrow (TV 2012)\", \n",
    "    'the_flash': \"The Flash (Comics)\", \n",
    "    'the_hobbit': \"The Hobbit - All Media Types\", \n",
    "    'the_song_of_achillles': \"The Song of Achilles - Madeline Miller\", \n",
    "    'the_witcher': \"The Witcher (TV)\", \n",
    "    'thor': \"Thor - All Media Types\", \n",
    "    'tiger&bunny': \"Tiger & Bunny\", \n",
    "    'tokyo_ghoul': \"Tokyo Ghoul\", \n",
    "    'transformers': \"Transformers - All Media Types\", \n",
    "    'umbrella_academy': \"The Umbrella Academy (TV)\", \n",
    "    'xmen': \"X-Men - All Media Types\", \n",
    "    'young_justice': \"Young Justice - All Media Types\", \n",
    "    'yuuri_on_ice': \"Yuri!!! on Ice (Anime)\", \n",
    "    'artemis_fowl': \"Artemis Fowl - Eoin Colfer\",\n",
    "     'big_hero_6': \"Big Hero 6 (2014)\",\n",
    "     'downton_abbey': \"Downton Abbey\",\n",
    "     'ouran_hshc': \"Ouran High School Host Club - All Media Types\",\n",
    "     'prince_of_tennis': \"Tennis no Oujisama | Prince of Tennis\",\n",
    "     'the_croods': \"The Croods (Movies)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2e3d19a3-b5f8-4392-b2b2-79677e1cb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function & code to convert my fandoms to ao3 fandoms\n",
    "def convert_my_fandoms_to_ao3_fandoms(dict):\n",
    "    for fic in dict:\n",
    "        clean_fandoms = []\n",
    "        for fandom in fic['fandom']:\n",
    "            if fandom in FANDOM_NAMES:\n",
    "                fandom = FANDOM_CONVERSION[fandom]\n",
    "            clean_fandoms.append(fandom)\n",
    "        fic['fandom'] = sorted(clean_fandoms)\n",
    "\n",
    "convert_my_fandoms_to_ao3_fandoms(non_standard_fandom_fics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d974428d-c2b6-4283-b8f5-7155f617748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all fandoms\n",
    "all_fandoms = set()\n",
    "\n",
    "for fic in non_standard_fandom_fics_dict:\n",
    "    for fandom in fic['fandom']: \n",
    "        all_fandoms.add(fandom)\n",
    "\n",
    "# sorted(list(all_fandoms)) # There should be NO \"CHANGE\" fandom and NONE of my fandoms left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9de37a00-557e-4aeb-8802-b1e4b7bf3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fandom standardized dict to JSON\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_ao3.json\", \"w\") as outfile:\n",
    "    json.dump(non_standard_fandom_fics_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ec39f",
   "metadata": {},
   "source": [
    "## Clean FFN fics of s4 fic url\n",
    "- **Problem:** Need to clean ffn fic urls (prev was only ao3)\n",
    "- **Thus:** I will clean\n",
    "- **Desired Result:** JSON of clean ffn.net fics\n",
    "\n",
    "Fill authors & fandoms manually -- couldn't figure out how to get past FFN CloudFlare with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c629090b-5a04-4273-889c-275e559d6bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version_num</th>\n",
       "      <th>smk_source</th>\n",
       "      <th>dtb_type</th>\n",
       "      <th>location</th>\n",
       "      <th>fic_id</th>\n",
       "      <th>url</th>\n",
       "      <th>categories</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>fandom_type</th>\n",
       "      <th>fandom</th>\n",
       "      <th>fic_status</th>\n",
       "      <th>title</th>\n",
       "      <th>is_coffee</th>\n",
       "      <th>fic_series</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>is_subbed</th>\n",
       "      <th>is_backedup</th>\n",
       "      <th>is_bookmarked</th>\n",
       "      <th>in_category</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>current_chapter</th>\n",
       "      <th>fic_rating</th>\n",
       "      <th>to_read_rating</th>\n",
       "      <th>to_read_description</th>\n",
       "      <th>is_finished_inputting_data</th>\n",
       "      <th>ffn_date_updated_2-4-23</th>\n",
       "      <th>ffn_date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>to_read</td>\n",
       "      <td>ffn_net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.fanfiction.net/s/12334156/4/Travelers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fullmetal_alchemist, avengers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RugitusAstra</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffn_net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.fanfiction.net/s/12783920/1/Authors-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>downton_abbey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mr. Chaos</td>\n",
       "      <td>610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffn_net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.fanfiction.net/s/13910770/1/Nest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>katekyo_hitman_reborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ourliazo</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffn_net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.fanfiction.net/s/14052100/1/Gaslight...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>katekyo_hitman_reborn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ourliazo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>8.0</td>\n",
       "      <td>v8_local_files</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffn_net</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://m.fanfiction.net/s/5645842/1/Rational-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>artemis_fowl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AnihyrMoonstar</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      version_num      smk_source dtb_type location  fic_id  \\\n",
       "1736          8.0  v8_local_files  to_read  ffn_net     NaN   \n",
       "3848          8.0  v8_local_files      NaN  ffn_net     NaN   \n",
       "3849          8.0  v8_local_files      NaN  ffn_net     NaN   \n",
       "3850          8.0  v8_local_files      NaN  ffn_net     NaN   \n",
       "3851          8.0  v8_local_files      NaN  ffn_net     NaN   \n",
       "\n",
       "                                                    url categories is_bold  \\\n",
       "1736  https://www.fanfiction.net/s/12334156/4/Travelers        NaN     NaN   \n",
       "3848  https://m.fanfiction.net/s/12783920/1/Authors-...        NaN     NaN   \n",
       "3849         https://m.fanfiction.net/s/13910770/1/Nest        NaN     NaN   \n",
       "3850  https://m.fanfiction.net/s/14052100/1/Gaslight...        NaN     NaN   \n",
       "3851  https://m.fanfiction.net/s/5645842/1/Rational-...        NaN     NaN   \n",
       "\n",
       "      fandom_type                         fandom  fic_status title is_coffee  \\\n",
       "1736          NaN  fullmetal_alchemist, avengers         NaN   NaN       NaN   \n",
       "3848          NaN                  downton_abbey         NaN   NaN       NaN   \n",
       "3849          NaN          katekyo_hitman_reborn         NaN   NaN       NaN   \n",
       "3850          NaN          katekyo_hitman_reborn         NaN   NaN       NaN   \n",
       "3851          NaN                   artemis_fowl         NaN   NaN       NaN   \n",
       "\n",
       "     fic_series          author length is_complete is_subbed is_backedup  \\\n",
       "1736        NaN    RugitusAstra     15         NaN       NaN         NaN   \n",
       "3848        NaN       Mr. Chaos    610         NaN       NaN         NaN   \n",
       "3849        NaN        Ourliazo      4         NaN       NaN         NaN   \n",
       "3850        NaN        Ourliazo    NaN         NaN       NaN         NaN   \n",
       "3851        NaN  AnihyrMoonstar     16         NaN       NaN         NaN   \n",
       "\n",
       "      is_bookmarked  in_category all_tags current_chapter  fic_rating  \\\n",
       "1736            NaN          NaN      NaN             NaN         NaN   \n",
       "3848            NaN          NaN      NaN             NaN         NaN   \n",
       "3849            NaN          NaN      NaN             NaN         NaN   \n",
       "3850            NaN          NaN      NaN             NaN         NaN   \n",
       "3851            NaN          NaN      NaN             NaN         NaN   \n",
       "\n",
       "     to_read_rating to_read_description is_finished_inputting_data  \\\n",
       "1736            NaN                 NaN                        NaN   \n",
       "3848            NaN                 NaN                        NaN   \n",
       "3849            NaN                 NaN                        NaN   \n",
       "3850            NaN                 NaN                        NaN   \n",
       "3851            NaN                 NaN                        NaN   \n",
       "\n",
       "     ffn_date_updated_2-4-23 ffn_date_added  \n",
       "1736                     NaN            NaN  \n",
       "3848                     NaN            NaN  \n",
       "3849                     NaN            NaN  \n",
       "3850                     NaN            NaN  \n",
       "3851                     NaN            NaN  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in relevant DF from very top\n",
    "ffn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "80891843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Num of fic_id's that are null: 0\""
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill fic_id & title\n",
    "for ind in ffn.index:\n",
    "    # Set fic_id\n",
    "    fic_id = re.compile(r'/s/(\\d+)').findall(ffn.loc[ind].url)\n",
    "    ffn.loc[ind, 'fic_id'] = int(fic_id[0])\n",
    "    \n",
    "    # Set title\n",
    "    title = re.compile(r'/s/\\d+/\\d+/(.+)').findall(ffn.loc[ind,'url'])[0] \\\n",
    "                .replace('-m-', \"'m-\") \\\n",
    "                .replace('-s-', \"'s-\") \\\n",
    "                .replace('-', \" \")\n",
    "    ffn.loc[ind, 'title'] = title\n",
    "        \n",
    "\n",
    "\"Num of fic_id's that are null: \" + str(len(ffn[pd.isnull(ffn.fic_id)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "95dd792c-7c48-43d9-8776-5001a5d19c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to merge ffn.net fics\n",
    "def merge_ffn_fic(parent_df, fic_id):\n",
    "    # Load in df of fics with given fic_id\n",
    "    df = parent_df[parent_df['fic_id'] == fic_id]\n",
    "\n",
    "    # Make sure there are NOT empty dfs\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: len 0\")\n",
    "        return {}     \n",
    "\n",
    "    # Get dict, remove NaN's & de-dup lists\n",
    "    cols = df.to_dict('list')\n",
    "    for key in cols:\n",
    "        cols[key] = list(set([ele for ele in cols[key] if not pd.isna(ele)]))\n",
    "\n",
    "    # Sort & clean various attributes\n",
    "    sorted_sources = sorted(cols['smk_source'], key = lambda source: float(source.split('_')[0][1:]))\n",
    "    clean_authors = list(set([author.replace(\",\", \"\") for author in cols['author']]))\n",
    "    sorted_versions = sorted(cols['version_num'])\n",
    "    sorted_locations = sorted(cols[\"location\"], key=lambda loc: LOCATION_ORDER[loc])\n",
    "    \n",
    "    \n",
    "    clean_dtbs = set()\n",
    "    for dtb_str in cols['dtb_type']:\n",
    "        new_dtbs = dtb_str.split(',')\n",
    "        for dtb in new_dtbs:\n",
    "            clean_dtbs.add(dtb.strip())\n",
    "    clean_dtbs = list(clean_dtbs)\n",
    "    sorted_dtbs = sorted(clean_dtbs, key=lambda dtb: DTB_ORDER[dtb])\n",
    "\n",
    "    clean_tags = set()\n",
    "    for tag_str in cols['all_tags']:\n",
    "        new_tags = tag_str.split(',')\n",
    "        for tag in new_tags:\n",
    "            clean_tags.add(tag.strip())\n",
    "    sorted_tags = sorted(list(clean_tags))\n",
    "    \n",
    "    avg_rating = None if len(cols['fic_rating']) == 0 else round(sum(cols['fic_rating'])/len(cols['fic_rating']), 2)\n",
    "    # print(cols['to_read_rating'])\n",
    "    int_tr = [int(rating) for rating in cols['to_read_rating']]\n",
    "    avg_tr_rating = None if len(cols['to_read_rating']) == 0 else round(sum(int_tr)/len(cols['to_read_rating']), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {'num_appeared': len(df),\n",
    "            'primary_version': \"\" if len(sorted_versions) == 0 else sorted_versions[0],\n",
    "            'version_num': sorted_versions,\n",
    "            'primary_source': \"\" if len(sorted_sources) == 0 else sorted_sources[0],\n",
    "             'smk_source': sorted_sources,\n",
    "            'primary_dtb': \"\" if len(sorted_dtbs) == 0 else sorted_dtbs[0],\n",
    "             'dtb_type': sorted_dtbs,\n",
    "            'primary_loction': \"\" if len(sorted_locations) == 0 else sorted_locations[0],\n",
    "             'location': sorted_locations,\n",
    "             'fic_id': int(fic_id),\n",
    "            'primary_url': \"\" if len(cols['url']) == 0 else cols['url'][0],\n",
    "             'url': cols['url'],\n",
    "             'categories': cols['categories'],\n",
    "             'is_bold': None if len(cols[\"is_bold\"]) == 0 else any(cols[\"is_bold\"]), \n",
    "             'fandom_type': cols['fandom_type'],\n",
    "             'fandom': cols['fandom'],\n",
    "             'fic_status': None, # this column is entirely empty\n",
    "             'title': \"\" if len(cols['title']) == 0 else cols['title'][0],\n",
    "             'is_coffee': None if len(cols[\"is_coffee\"]) == 0 else any(cols[\"is_coffee\"]), \n",
    "             'fic_series': cols['fic_series'],\n",
    "             'author': clean_authors,\n",
    "             'length': None if len(cols[\"length\"]) == 0 else max(cols[\"length\"]),\n",
    "             'is_complete': None if len(cols[\"is_complete\"]) == 0 else any(cols[\"is_complete\"]), \n",
    "             'is_subbed': None if len(cols[\"is_subbed\"]) == 0 else any(cols[\"is_subbed\"]), \n",
    "             'is_backedup': None if len(cols[\"is_backedup\"]) == 0 else any(cols[\"is_backedup\"]), \n",
    "             'is_bookmarked': None if len(cols[\"is_bookmarked\"]) == 0 else any(cols[\"is_bookmarked\"]), \n",
    "             'in_category': None, # this column is entirely empty\n",
    "             'all_tags': sorted_tags,\n",
    "             'current_chapter': \"\" if len(cols[\"current_chapter\"]) == 0 else max(cols[\"current_chapter\"]),\n",
    "             'fic_rating': avg_rating, \n",
    "             'to_read_rating': avg_tr_rating,\n",
    "             'to_read_description': cols['to_read_description'],\n",
    "             'is_finished_inputting_data': None if len(cols[\"is_finished_inputting_data\"]) == 0 else any(cols[\"is_finished_inputting_data\"]), \n",
    "             'ffn_date_updated_2-4-23': cols['ffn_date_updated_2-4-23'],\n",
    "             'ffn_date_added': cols['ffn_date_added']}\n",
    "\n",
    "# merge_ffn_fic(ffn, 10747630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "358b4e20-e71c-4c24-a95c-3da5c5263eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to merge all ffn.net fics\n",
    "unique_fic_ids = ffn.fic_id.drop_duplicates().sort_values().to_list()\n",
    "merged_rows = []\n",
    "\n",
    "for i, id in enumerate(unique_fic_ids): \n",
    "    merged_row = merge_ffn_fic(ffn, id)\n",
    "    merged_rows.append(merged_row)\n",
    "    \n",
    "merged_df = pd.DataFrame(merged_rows).sort_values(by=\"fic_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "99f34332-da8f-4d0d-9f1a-80a51770ff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split & sort fandoms\n",
    "split_and_sort_fandoms(merged_rows)\n",
    "\n",
    "# Check for compacted fandoms\n",
    "for fic in merged_rows:\n",
    "    for fandom_str in fic['fandom']:\n",
    "        if ',' in fandom_str:\n",
    "            print(fic['fandom'])\n",
    "\n",
    "# Printing none means it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6f1e10ff-321e-43cf-9a53-541d5b8364bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fandoms in ffn \n",
    "convert_my_fandoms_to_ao3_fandoms(merged_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "cd3c1090-0754-41fa-85ce-7c5a95e523ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fandom standardized dict to JSON\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_ffn.json\", \"w\") as outfile:\n",
    "    json.dump(merged_rows, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd7a42-ce74-4eba-a277-a89d5af37490",
   "metadata": {},
   "source": [
    "## Clean OTH fics of s4 fic url\n",
    "- **Problem:** Need to other fic urls \n",
    "- **Thus:** I will clean\n",
    "- **Desired Result:** JSON of clean oth fics\n",
    "\n",
    "Did manually, there were only 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8e74b073-66f6-4b1f-80eb-5e731bf313c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version_num</th>\n",
       "      <th>smk_source</th>\n",
       "      <th>dtb_type</th>\n",
       "      <th>location</th>\n",
       "      <th>fic_id</th>\n",
       "      <th>url</th>\n",
       "      <th>categories</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>fandom_type</th>\n",
       "      <th>fandom</th>\n",
       "      <th>fic_status</th>\n",
       "      <th>title</th>\n",
       "      <th>is_coffee</th>\n",
       "      <th>fic_series</th>\n",
       "      <th>author</th>\n",
       "      <th>length</th>\n",
       "      <th>is_complete</th>\n",
       "      <th>is_subbed</th>\n",
       "      <th>is_backedup</th>\n",
       "      <th>is_bookmarked</th>\n",
       "      <th>in_category</th>\n",
       "      <th>all_tags</th>\n",
       "      <th>current_chapter</th>\n",
       "      <th>fic_rating</th>\n",
       "      <th>to_read_rating</th>\n",
       "      <th>to_read_description</th>\n",
       "      <th>is_finished_inputting_data</th>\n",
       "      <th>ffn_date_updated_2-4-23</th>\n",
       "      <th>ffn_date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>7.0</td>\n",
       "      <td>v7_toread</td>\n",
       "      <td>to_read</td>\n",
       "      <td>pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://drive.google.com/drive/u/0/folders/1mx...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>merlin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>More Lovely and More Temperate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saucery,</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>gender-swapping spell on Arthur, smut</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.0</td>\n",
       "      <td>v7_ffn</td>\n",
       "      <td>read</td>\n",
       "      <td>tum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://kristtorn.tumblr.com/post/166530149542...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>harry_potter,bnha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divergent Bindings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Araceil,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     version_num smk_source dtb_type location  fic_id  \\\n",
       "315          7.0  v7_toread  to_read      pdf     NaN   \n",
       "97           7.0     v7_ffn     read      tum     NaN   \n",
       "\n",
       "                                                   url categories is_bold  \\\n",
       "315  https://drive.google.com/drive/u/0/folders/1mx...        NaN     NaN   \n",
       "97   https://kristtorn.tumblr.com/post/166530149542...        NaN    True   \n",
       "\n",
       "     fandom_type             fandom  fic_status  \\\n",
       "315          NaN             merlin         NaN   \n",
       "97           NaN  harry_potter,bnha         NaN   \n",
       "\n",
       "                              title is_coffee fic_series    author length  \\\n",
       "315  More Lovely and More Temperate       NaN        NaN  Saucery,      8   \n",
       "97               Divergent Bindings       NaN        NaN  Araceil,    NaN   \n",
       "\n",
       "    is_complete is_subbed is_backedup  is_bookmarked  in_category all_tags  \\\n",
       "315         NaN       NaN         NaN            NaN          NaN      NaN   \n",
       "97        False       NaN         NaN            NaN          NaN      NaN   \n",
       "\n",
       "    current_chapter  fic_rating to_read_rating  \\\n",
       "315               -         NaN              1   \n",
       "97              NaN         NaN            NaN   \n",
       "\n",
       "                       to_read_description is_finished_inputting_data  \\\n",
       "315  gender-swapping spell on Arthur, smut                       True   \n",
       "97                                     NaN                      False   \n",
       "\n",
       "    ffn_date_updated_2-4-23 ffn_date_added  \n",
       "315                     NaN            NaN  \n",
       "97                      NaN            NaN  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in relevant DF from very top\n",
    "oth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8c4a3f81-9993-40fa-b5d6-80d58b4b9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge oth fics\n",
    "def merge_oth(parent_df, title):\n",
    "    # Load in df of fics with given fic_id\n",
    "    df = parent_df[parent_df['title'] == title]\n",
    "\n",
    "    # Make sure there are NOT empty dfs\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: len 0\")\n",
    "        return {}     \n",
    "\n",
    "    # Get dict, remove NaN's & de-dup lists\n",
    "    cols = df.to_dict('list')\n",
    "    for key in cols:\n",
    "        cols[key] = list(set([ele for ele in cols[key] if not pd.isna(ele)]))\n",
    "\n",
    "    avg_rating = None if len(cols['fic_rating']) == 0 else round(sum(cols['fic_rating'])/len(cols['fic_rating']), 2)\n",
    "    int_tr = [int(rating) for rating in cols['to_read_rating']]\n",
    "    avg_tr_rating = None if len(cols['to_read_rating']) == 0 else round(sum(int_tr)/len(cols['to_read_rating']), 2)\n",
    "\n",
    "    # Sort & clean various attributes\n",
    "    sorted_sources = sorted(cols['smk_source'], key = lambda source: float(source.split('_')[0][1:]))\n",
    "    clean_authors = list(set([author.replace(\",\", \"\") for author in cols['author']]))\n",
    "    sorted_versions = sorted(cols['version_num'])\n",
    "    sorted_locations = sorted(cols[\"location\"], key=lambda loc: LOCATION_ORDER[loc])\n",
    "    \n",
    "    \n",
    "    clean_dtbs = set()\n",
    "    for dtb_str in cols['dtb_type']:\n",
    "        new_dtbs = dtb_str.split(',')\n",
    "        for dtb in new_dtbs:\n",
    "            clean_dtbs.add(dtb.strip())\n",
    "    clean_dtbs = list(clean_dtbs)\n",
    "    sorted_dtbs = sorted(clean_dtbs, key=lambda dtb: DTB_ORDER[dtb])\n",
    "\n",
    "    clean_tags = set()\n",
    "    for tag_str in cols['all_tags']:\n",
    "        new_tags = tag_str.split(',')\n",
    "        for tag in new_tags:\n",
    "            clean_tags.add(tag.strip())\n",
    "    sorted_tags = sorted(list(clean_tags))\n",
    " \n",
    "    \n",
    "    # return cols\n",
    "    return {'num_appeared': len(df),\n",
    "            'primary_version': \"\" if len(sorted_versions) == 0 else sorted_versions[0],\n",
    "            'version_num': sorted_versions,\n",
    "            'primary_source': \"\" if len(sorted_sources) == 0 else sorted_sources[0],\n",
    "             'smk_source': sorted_sources,\n",
    "            'primary_dtb': \"\" if len(sorted_dtbs) == 0 else sorted_dtbs[0],\n",
    "             'dtb_type': sorted_dtbs,\n",
    "            'primary_loction': \"\" if len(sorted_locations) == 0 else sorted_locations[0],\n",
    "             'location': sorted_locations,\n",
    "             'fic_id': cols[\"fic_id\"], # they all have fic_ids\n",
    "            'primary_url': \"\" if len(cols['url']) == 0 else cols['url'][0],\n",
    "             'url': cols['url'],\n",
    "             'categories': cols['categories'],\n",
    "             'is_bold': None if len(cols[\"is_bold\"]) == 0 else any(cols[\"is_bold\"]), \n",
    "             'fandom_type': cols['fandom_type'],\n",
    "             'fandom': cols['fandom'],\n",
    "             'fic_status': None, # this column is entirely empty\n",
    "             'title': \"\" if len(cols['title']) == 0 else cols['title'][0],\n",
    "             'is_coffee': None if len(cols[\"is_coffee\"]) == 0 else any(cols[\"is_coffee\"]), \n",
    "             'fic_series': cols['fic_series'],\n",
    "             'author': clean_authors,\n",
    "             'length': None if len(cols[\"length\"]) == 0 else max(cols[\"length\"]),\n",
    "             'is_complete': None if len(cols[\"is_complete\"]) == 0 else any(cols[\"is_complete\"]), \n",
    "             'is_subbed': None if len(cols[\"is_subbed\"]) == 0 else any(cols[\"is_subbed\"]), \n",
    "             'is_backedup': None if len(cols[\"is_backedup\"]) == 0 else any(cols[\"is_backedup\"]), \n",
    "             'is_bookmarked': None if len(cols[\"is_bookmarked\"]) == 0 else any(cols[\"is_bookmarked\"]), \n",
    "             'in_category': None, # this column is entirely empty\n",
    "             'all_tags': sorted_tags,\n",
    "             'current_chapter': \"\" if len(cols[\"current_chapter\"]) == 0 else max(cols[\"current_chapter\"]),\n",
    "             'fic_rating': avg_rating, \n",
    "             'to_read_rating': avg_tr_rating,\n",
    "             'to_read_description': cols['to_read_description'],\n",
    "             'is_finished_inputting_data': None if len(cols[\"is_finished_inputting_data\"]) == 0 else any(cols[\"is_finished_inputting_data\"]), \n",
    "             'ffn_date_updated_2-4-23': cols['ffn_date_updated_2-4-23'],\n",
    "             'ffn_date_added': cols['ffn_date_added']}\n",
    "\n",
    "# Testing\n",
    "# merge_oth(oth, 'Divergent Bindings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9b9c4176-1be3-4065-8099-547c01ac5719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to merge all oth fics\n",
    "titles = oth.title.drop_duplicates().sort_values().to_list()\n",
    "merged_rows = []\n",
    "\n",
    "for i, title in enumerate(titles): \n",
    "    merged_row = merge_oth(oth, title)\n",
    "    merged_rows.append(merged_row)\n",
    "    \n",
    "merged_df = pd.DataFrame(merged_rows).sort_values(by=\"fic_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b91c0276-7714-4aba-9f92-c1f66ac624dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fandoms in oth \n",
    "convert_my_fandoms_to_ao3_fandoms(merged_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a2404ff9-44d2-4d9a-be65-164095469a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fandom standardized dict to JSON\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_oth.json\", \"w\") as outfile:\n",
    "    json.dump(merged_rows, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877ca9e",
   "metadata": {},
   "source": [
    "## Combine ao3, ffn.net, and oth JSON files -> s5 fic url\n",
    "- **Problem:** Need to connect all 3\n",
    "- **Thus:** Will do\n",
    "- **Desired Result:** JSON of all s4 fic urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ccff5c99-a7ea-433b-a568-621ae9635d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant files\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_ao3.json\", \"r\") as infile:\n",
    "    ao3 = json.load(infile)\n",
    "\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_ffn.json\", \"r\") as infile:\n",
    "    ffn = json.load(infile)\n",
    "\n",
    "with open(\"clean_data_4/all_versions_fic_url_done_oth.json\", \"r\") as infile:\n",
    "    oth = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "faddba0d-fa24-4bd2-98a5-e17162887803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the 3 files\n",
    "combined_dict = ao3 + ffn + oth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8936cdb7-b2ce-4a1a-a7a6-ce3e7cbf921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to s5 fic url \n",
    "# with open(\"clean_data_5/fic_url.json\", \"w\") as outfile:\n",
    "#     json.dump(combined_dict, outfile) DO NOT RUN, DID SOME MANUAL DATA CLEANING RE: ffn-ao3 same fics when merging s5 fic url + text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72726569-4784-45ee-838c-65efd899f8f2",
   "metadata": {},
   "source": [
    "## Convert s4 series text -> s5 series text\n",
    "- **Problem:** Haven't done s5 series text yet\n",
    "- **Thus:** Will do\n",
    "- **Desired Result:** De-dupped s5 series text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcef2ddf-e929-4751-9131-973b2a2bfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in relevant files\n",
    "s4_series_text = pd.read_csv(\"clean_data_4/all_versions_series_text.csv\", index_col=0, encoding=\"utf-8-sig\").reset_index(drop=True)\n",
    "s4_series_text['title'] = s4_series_text['title'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03d71fa-6018-484f-a3d0-ee0bd75deb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_on_title(parent_df, title):\n",
    "    \"\"\"\n",
    "    Takes a coffee df (df), either text or url, ideally of multiple rows.\n",
    "    Merges data, as specificed below, into a single row.\n",
    "    Returns author dict of merged info (dict).\n",
    "    \"\"\"\n",
    "    # Load in df of fics with given fic_id\n",
    "    df = parent_df[parent_df['title'] == title]\n",
    "\n",
    "    # Make sure there are NOT empty dfs\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: len 0\")\n",
    "        return {}     \n",
    "\n",
    "    # Get dict, remove NaN's & de-dup lists\n",
    "    cols = df.to_dict('list')\n",
    "    for key in cols:\n",
    "        cols[key] = list(set([ele for ele in cols[key] if not pd.isna(ele)]))\n",
    "\n",
    "    # Sort & clean various attributes\n",
    "    sorted_versions = sorted(cols['version_num'])\n",
    "    sorted_sources = sorted(cols['smk_source'], key = lambda source: float(source.split('_')[0][1:]))\n",
    "    clean_authors = [author.replace(\",\", \"\") for author in cols['author']]\n",
    "    sorted_locations = sorted(cols[\"location\"], key=lambda loc: LOCATION_ORDER[loc])\n",
    "\n",
    "    clean_dtbs = set()\n",
    "    for dtb_str in cols['dtb_type']:\n",
    "        new_dtbs = dtb_str.split(',')\n",
    "        for dtb in new_dtbs:\n",
    "            clean_dtbs.add(dtb.strip())\n",
    "    clean_dtbs = list(clean_dtbs)\n",
    "    sorted_dtbs = sorted(clean_dtbs, key=lambda dtb: DTB_ORDER[dtb])\n",
    "    \n",
    "    avg_rating = None if len(cols['series_rating']) == 0 else round(sum(cols['series_rating'])/len(cols['series_rating']), 2)\n",
    "\n",
    "    return {'num_appeared': len(df),\n",
    "            'primary_version': \"\" if len(sorted_versions) == 0 else sorted_versions[0],\n",
    "            'version_nums': sorted_versions,\n",
    "             'primary_source': \"\" if len(sorted_sources) == 0 else sorted_sources[0],\n",
    "             'smk_source': sorted_sources,\n",
    "             'primary_dtb': \"\" if len(sorted_dtbs) == 0 else sorted_dtbs[0],\n",
    "             'dtb_type': sorted_dtbs,\n",
    "             'primary_location': \"\" if len(sorted_locations) == 0 else sorted_locations[0],\n",
    "             'locations': sorted_locations,\n",
    "             'fandom_type': sorted(cols[\"fandom_type\"]),\n",
    "             'fandom': sorted(cols[\"fandom\"]),\n",
    "             'categories': sorted(cols[\"categories\"]),\n",
    "             'series_status': \"\" if len(cols[\"series_status\"]) == 0 else cols[\"series_status\"][0],\n",
    "             'is_bold': None if len(cols[\"is_bold\"]) == 0 else any(cols[\"is_bold\"]),\n",
    "             'title': title,\n",
    "             'author': sorted(clean_authors),\n",
    "             'is_coffee': None if len(cols[\"is_coffee\"]) == 0 else any(cols[\"is_coffee\"]),\n",
    "             'is_complete': None if len(cols[\"is_complete\"]) == 0 else any(cols[\"is_complete\"]),\n",
    "             'is_subbed': None if len(cols[\"is_subbed\"]) == 0 else any(cols[\"is_subbed\"]),\n",
    "             'is_bookmarked': None if len(cols[\"is_bookmarked\"]) == 0 else any(cols[\"is_bookmarked\"]),\n",
    "             'current_chapter': None if len(cols[\"current_chapter\"]) == 0 else max(cols[\"current_chapter\"]),\n",
    "             'series_length': None if len(cols[\"series_length\"]) == 0 else max(cols[\"series_length\"]),\n",
    "             'series_rating': avg_rating,\n",
    "             'all_tags': cols[\"all_tags\"],\n",
    "             'is_finished_inputting_info': None if len(cols[\"is_finished_inputting_info\"]) == 0 else any(cols[\"is_finished_inputting_info\"]),\n",
    "           }\n",
    "\n",
    "# Testing\n",
    "# merge_on_title(s4_series_text, \"a love story for the ages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "46d76992-9a39-4b23-8836-6c520310edd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code to merge all series\n",
    "all_titles = sorted(oth.title.unique())\n",
    "merged_series = []\n",
    "\n",
    "for title in all_titles: \n",
    "    new_series = merge_oth(oth, title)\n",
    "    merged_series.append(new_series)\n",
    "\n",
    "# Create & sort results \n",
    "merged_series_df = pd.DataFrame(merged_series).sort_values(by=\"title\").reset_index(drop=True)\n",
    "merged_series = sorted(merged_series, key=lambda fic: fic['title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b4b10a68-3f36-4959-925a-11ab99f869eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to JSON\n",
    "with open(\"clean_data_5/series_text.json\", \"w\") as outfile:\n",
    "    json.dump(merged_series, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "afce1ccc-b4f3-4950-84b4-4c96eaff88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in relevant files\n",
    "with open(\"clean_data_5/fic_url.json\", \"r\") as infile:\n",
    "    fic_url = json.load(infile)\n",
    "\n",
    "fic_text = pd.read_csv(\"clean_data_5/fic_text.csv\", index_col=0, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fef87-f4e6-4dd0-855e-b118ece3a7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "163615d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fic_equal(row1, row2) -> bool:\n",
    "    \"\"\"\n",
    "    Takes two fic or series rows from a database (df).\n",
    "    Compares them to determine if they're the same fic.\n",
    "    Returns a boolean of whether or not they're equal (bool).\n",
    "    \"\"\"\n",
    "    # Get titles boolean\n",
    "    title1 = str(row1['title']).lower().strip()\n",
    "    title2 = str(row2['title']).lower().strip()\n",
    "    same_title = title1 == title2\n",
    "    \n",
    "    # Get authors boolean (strip, lower, not empty)\n",
    "    authlist1 = [] if pd.isnull(row1['author']) else row1['author'].split(',')\n",
    "    authlist2 = [] if pd.isnull(row2['author']) else row2['author'].split(',')\n",
    "    author1 = set([auth.lower().strip() for auth in authlist1 if auth != ''])\n",
    "    author2 = set([auth.lower().strip() for auth in authlist2 if auth != ''])\n",
    "    \n",
    "    same_author = (author1 == author2) or (not author1 and not author2)\n",
    "    absent_author = not author1 or not author2\n",
    "\n",
    "    # Get locations boolean\n",
    "    same_location = (row1['location'] == row2['location']) or \\\n",
    "        pd.isnull(row1['location']) or pd.isnull(row2['location'])\n",
    "    \n",
    "    # Get fandoms boolean\n",
    "    same_fandoms = False\n",
    "    if not pd.isnull(row1['fandom']) and not pd.isnull(row2['fandom']):\n",
    "        fandom1 = [fan.strip() for fan in row1['fandom'].split(',')]\n",
    "        fandom2 = [fan.strip() for fan in row2['fandom'].split(',')]\n",
    "        diff = set(fandom1) ^ set(fandom2)\n",
    "        same_fandoms = (len(diff) == 0) or (diff == {'dcu', 'batman'}) or \\\n",
    "            (diff == {'spiderman', 'avengers'})\n",
    "        \n",
    "    \n",
    "    # print(f'same_title: {same_title}, same_fandoms: {same_fandoms}, same_author: {same_author}, absent_author: {absent_author}')\n",
    "    # print()\n",
    "    return same_title and same_fandoms and (same_author or (absent_author and same_location))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdb14b",
   "metadata": {},
   "source": [
    "# WORKSPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0a00c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (1847062757.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    'fairy_tail': 'Fairy Tail,\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Partially complete dict of ALL fandom names\n",
    "{'1/2_prince': '1/2 Wangzi | 1/2 Prince',\n",
    " '2ha': \"二哈和他的白猫师尊 - 肉包不吃肉 | The Husky and His White Cat Shizun - Meatbun Doesn't Eat Meat\",\n",
    " 'agents_of_shield': 'Agents of S.H.I.E.L.D. (TV)',\n",
    " 'arrow': 'Arrow (TV 2012)',\n",
    " 'artemis_fowl':  'Artemis Fowl - Eoin Colfer',\n",
    " 'assassins_creed': \"Assassin's Creed - All Media Types\",\n",
    " 'at_the_end_of_the_road': '그 끝에 있는 것 | At the End of the Road (Webcomic)',\n",
    " 'ateez_band':  'ATEEZ (Band)',\n",
    " 'atla':  'Avatar: The Last Airbender',\n",
    " 'attack_on_titan': 'Shingeki no Kyojin | Attack on Titan',\n",
    " 'avatar': 'Avatar (Cameron Movies)',\n",
    " 'avengers': 'Avengers (Marvel) - All Media Types',\n",
    " 'batman': 'Batman - All Media Types',\n",
    " 'batman_2022': 'The Batman (Movie 2022)',\n",
    " 'big_hero_6': 'Big Hero 6 (2014)',\n",
    " 'black_butler': 'Kuroshitsuji | Black Butler',\n",
    " 'black_panther': 'Black Panther (2018)',\n",
    " 'bleach': 'Bleach',\n",
    " 'bnha': '僕のヒーローアカデミア | Boku no Hero Academia | My Hero Academia',\n",
    " 'books_of_the_raksura': 'Books of the Raksura - Martha Wells',\n",
    " 'brooklyn_99': 'Brooklyn Nine-Nine (TV)',\n",
    " 'bts': '방탄소년단 | Bangtan Boys | BTS',\n",
    " 'captain_america':  'Captain America (Movies)',\n",
    " 'captive_prince': 'Captive Prince - C. S. Pacat',\n",
    " 'castlevania': 'Castlevania (Cartoon 2017-2021)',\n",
    " 'chronicles_of_narnia':  'Chronicles of Narnia - C. S. Lewis',\n",
    " 'code_geass':  'Code Geass',\n",
    " 'criminal_minds':  'Criminal Minds',\n",
    " 'damien': 'Damien (TV)',\n",
    " 'danny_phantom':  'Danny Phantom',\n",
    " 'daredevil':  'Daredevil (TV)',\n",
    " 'dark_angel': 'Dark Angel (TV)',\n",
    " 'dcu': 'DCU',\n",
    " 'deadpool':  'Deadpool - All Media Types',\n",
    " 'death_note':  'Death Note',\n",
    " 'descendants': 'Descendants (Disney Movies)',\n",
    " 'detroit_become_human': 'Detroit: Become Human (Video Game)',\n",
    " 'doctor_strange': 'Doctor Strange (Movies)Navigation and Actions',\n",
    " 'downton_abbey': 'Downton Abbey',\n",
    " 'eyeshield_21': 'Eyeshield 21',\n",
    " 'fairy_tail': 'Fairy Tail,\n",
    " 'fantastic_four': 'Fantastic Four',\n",
    " 'fast&furious': 'Fast & Furious (Movies),\n",
    " 'fbawtft': 'Fantastic Beasts and Where to Find Them (Movies)',\n",
    " 'final_fantasy_vii': 'Compilation of Final Fantasy VII',\n",
    " 'final_fantasy_viii': 'Final Fantasy VIII',\n",
    " 'final_fantasy_xv': 'Final Fantasy XV',\n",
    " 'folklore': 'folklore',\n",
    " 'frozen': 'Frozen (Disney Movies)',\n",
    " 'fullmetal_alchemist': 'Fullmetal Alchemist - All Media Types',\n",
    " 'game_of_thrones': 'Game of Thrones (TV)',\n",
    " 'good_omens': 'Good Omens (TV)',\n",
    " 'gotham':'Gotham (TV)',\n",
    " 'gravity_falls': 'Gravity Falls',\n",
    " 'guardians_of_the_galaxy': 'Guardians of the Galaxy (Movies)',\n",
    " 'gundam_wing_ac': 'Gundam Wing',\n",
    " 'hamilton': 'Hamilton - Miranda',\n",
    " 'hannibal': 'Hannibal (TV)',\n",
    " 'harry_potter': 'Harry Potter - J. K. Rowling',\n",
    " 'hells_kitchen': \"Hell's Kitchen (US TV) RPF\",\n",
    " 'highschool_of_the_dead': 'Gakuen Mokushiroku | Highschool of the Dead',\n",
    " 'house_of_the_dragon': 'House of the Dragon (TV)',\n",
    " 'httyd': 'How to Train Your Dragon (Movies)',\n",
    " 'hunger_games': 'Hunger Games Series - All Media Types',\n",
    " 'iron_man': 'Iron Man (Movies)',\n",
    " 'james_bond': 'James Bond',\n",
    " 'john_wick': 'John Wick (Movies)',\n",
    " 'joy_of_life': '庆余年 | Joy of Life (TV)Navigation and Actions',\n",
    " 'jurassic_park': 'Jurassic Park - All Media Types',\n",
    " 'justice_league': 'Justice League - All Media Types',\n",
    " 'k_anime',\n",
    " 'katekyo_hitman_reborn',\n",
    " 'kingsman',\n",
    " 'kung_fu_panda',\n",
    " 'kuroko_no_basuke',\n",
    " 'left4dead',\n",
    " 'legend_of_korra',\n",
    " 'leverage',\n",
    " 'loki',\n",
    " 'lord_of_the_rings',\n",
    " 'lucifer',\n",
    " 'magi_lom',\n",
    " 'magnus_files',\n",
    " 'matilda',\n",
    " 'mcu',\n",
    " 'mdzs',\n",
    " 'megamind',\n",
    " 'men_in_black',\n",
    " 'merlin',\n",
    " 'minecraft',\n",
    " 'miraculous_ladybug',\n",
    " 'mob_psycho',\n",
    " 'monster_hunter',\n",
    " 'moon_knight',\n",
    " 'multiple_fandoms',\n",
    " 'my_next_life_as_a_villainess',\n",
    " 'naruto',\n",
    " 'ncis',\n",
    " 'nirvana_in_fire',\n",
    " 'none_placeholder',\n",
    " 'none_unsorted',\n",
    " 'once_upon_a_time',\n",
    " 'one_piece',\n",
    " 'one_punch_man',\n",
    " 'original_work',\n",
    " 'other',\n",
    " 'our_flag_means_death',\n",
    " 'ouran_hshc',\n",
    " 'pacific_rim',\n",
    " 'percy_jackson_olympians',\n",
    " 'person_of_interest',\n",
    " 'phineas_and_ferb',\n",
    " 'pkmn_sword&shield',\n",
    " 'pokemon',\n",
    " 'pokemon_detective_pikachu',\n",
    " 'prince_of_tennis',\n",
    " 'princess_kaguya',\n",
    " 'reincarnated_as_a_sword',\n",
    " 'rise_of_the_guardians',\n",
    " 'riverdale',\n",
    " 'rwby',\n",
    " 'shadow_and_bone',\n",
    " 'sherlock',\n",
    " 'six_of_crows',\n",
    " 'smallville',\n",
    " 'solo_levelling',\n",
    " 'soul_eater',\n",
    " 'spiderman',\n",
    " 'spiderverse',\n",
    " 'star_wars',\n",
    " 'star_wars_cw',\n",
    " 'stargate',\n",
    " 'stargate_atlantis',\n",
    " 'stranger_things',\n",
    " 'suicide_squad',\n",
    " 'supernatural',\n",
    " 'svsss',\n",
    " 'sword_art_online',\n",
    " 'tangled',\n",
    " 'teen_titans',\n",
    " 'teen_wolf',\n",
    " 'temeraire',\n",
    " 'tgcf',\n",
    " 'the defenders',\n",
    " 'the_100',\n",
    " 'the_arrow',\n",
    " 'the_croods',\n",
    " 'the_flash',\n",
    " 'the_hobbit',\n",
    " 'the_kane_chronicles',\n",
    " 'the_kings_avatar',\n",
    " 'the_last_of_us',\n",
    " 'the_punisher',\n",
    " 'the_song_of_achillles',\n",
    " 'the_witcher',\n",
    " 'thor',\n",
    " 'tiger&bunny',\n",
    " 'tokyo_ghoul',\n",
    " 'torchwood',\n",
    " 'transformers',\n",
    " 'travelers',\n",
    " 'twilight',\n",
    " 'umbrella_academy',\n",
    " 'vampire_hunter_d',\n",
    " 'venom',\n",
    " 'voltron',\n",
    " 'welcome_to_nightvale',\n",
    " 'wicked',\n",
    " 'winx_club',\n",
    " 'xmen',\n",
    " 'yona_of_the_dawn',\n",
    " 'young_hercules',\n",
    " 'young_justice',\n",
    " 'yuuri_on_ice',\n",
    " 'zootopia'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
