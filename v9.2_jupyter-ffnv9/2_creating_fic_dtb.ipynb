{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135af629",
   "metadata": {},
   "source": [
    "# Completing ficDTB & Filling in All Fic Info\n",
    "- <b>Name:</b> Sofia Kobayashi\n",
    "- <b>Date:</b> 02/01/2023\n",
    "- <b>Notebook Stage:</b> 1.1 (using inital data collected to complete ficDTB)\n",
    "- <b>Description:</b> Combining ALL fic data (mostly adding text-data fics & fics from FFN.ne& AO3 sub/bookmarks list)\n",
    "\n",
    "### **<u>Table of Contents</u>**\n",
    "\n",
    "1. **[Imports](#imports)**\n",
    "\n",
    "1. Fill AO3 fics from fic-3\n",
    "\n",
    "\n",
    "1. **[Adding other url-data fics to ficDTB](#otherUrl_1)**\n",
    "    1. [Adding info from otherDTB](#otherUrl_1_1)\n",
    "        - Add fics to ficDTB from otherDTB (ffn.net fics & ao3 external fics)\n",
    "        - Add users to userDTB from otherDTB (ffn.net users)\n",
    "            - **Other CHECKPOINT NUM** - DESCRIPTION\n",
    "    1. [Adding FFN.net fics & users](#otherUrl_1_2)\n",
    "        - **User CHECKPOINT NUM** - DESCRIPTION\n",
    "        - **Fic CHECKPOINT NUM** - DESCRIPTION\n",
    "    1. [Adding AO3 fics](#otherUrl_1_3)\n",
    "1. **[Adding text-data fics (from previous versions) to ficDTB](#TAG)**\n",
    "1. **[TITLE](#TAG)**\n",
    "1. **[TITLE](#TAG)**\n",
    "    - **Fic CHECKPOINT NUM** - DESCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a882f0",
   "metadata": {},
   "source": [
    "### Plans for this Notebook \n",
    "- bring over excess stuff from dtbs_from_prev\n",
    "\n",
    "- **add all fic urls for the other DTBs to ficDTB (location_found will just be different**\n",
    "    - add look_into from others -> look_into dtb (no)\n",
    "\n",
    "- Grab fics from ffn.net (Follows & Favorites) & ao3 (bookmarks, subs, for later)\n",
    "    - add to ficDTB\n",
    "- populate ficDTB\n",
    "- add text fics\n",
    "    - add date_added & versionNum from v1-6 if possible to text fics, which are then added\n",
    "- de-dup (same fic-diff places, etc.)\n",
    "    - start making search/matching functions for text, ffn.net, version matching\n",
    "- another other cleaning? DTB seperation? \n",
    "\n",
    "\n",
    "### Plans for next notebooks\n",
    "- next notebook is cleaning up all non-fic dtbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beed84b",
   "metadata": {},
   "source": [
    "### AO3 Work Methods\n",
    "bookmark\n",
    ", collect\n",
    ", comment\n",
    ", delete_bookmark\n",
    ", download\n",
    ", download_to_file\n",
    ", get\n",
    ", get_comments\n",
    ", get_images\n",
    ", is_subscribed\n",
    ", leave_kudos\n",
    ", load_chapters\n",
    ", request\n",
    ", reload\n",
    ", set_session\n",
    ", str_format\n",
    ", subscribe\n",
    ", unsubscribe\n",
    "\n",
    "\n",
    "### AO3 Stats\n",
    "t2 = ['authors',\n",
    " 'bookmarks',\n",
    " 'categories',\n",
    " 'chapters',\n",
    " 'characters',\n",
    " 'collections',\n",
    " 'comments',\n",
    " 'complete',\n",
    " 'date_edited',\n",
    " 'date_published',\n",
    " 'date_updated',\n",
    " 'end_notes',\n",
    " 'expected_chapters',\n",
    " 'fandoms',\n",
    " 'hits',\n",
    " 'id',\n",
    " 'is_subscribed',\n",
    " 'kudos',\n",
    " 'language',\n",
    " 'loaded',\n",
    " 'metadata',\n",
    " 'nchapters',\n",
    " 'oneshot',\n",
    " 'rating',\n",
    " 'relationships',\n",
    " 'restricted',\n",
    " 'series',\n",
    " 'start_notes',\n",
    " 'status',\n",
    " 'summary',\n",
    " 'tags',\n",
    " 'text',\n",
    " 'title',\n",
    " 'url',\n",
    " 'words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12c644",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac022ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29041df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers.ipynb\n",
    "import AO3\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import difflib\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0795d",
   "metadata": {},
   "source": [
    "<a id=\"sec2\"></a>\n",
    "## 2. Filling AO3 ficDTB (from fic-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e990e9",
   "metadata": {},
   "source": [
    "<a id=\"sec2.1\"></a>\n",
    "### 2.1 Defining ficDTB-filling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_columns = {'location_found', 'dtb_type', 'smk_source', 'version',\n",
    "       'date_added', 'date_last_viewed', 'url_type', 'id', 'url',\n",
    "       'recced_from_collections', 'url_psueds', 'fic_obj', 'date_obj_updated',\n",
    "       'is_subscribed', 'cur_chapter', 'my_notes', 'title', 'authors', 'fandoms',\n",
    "       'rating', 'categories', 'warnings', 'relationships', 'characters',\n",
    "       'tags', 'series', 'collections', 'words', 'nchapters',\n",
    "       'expected_chapters', 'complete', 'date_published', 'date_updated',\n",
    "       'date_edited', 'language', 'is_restricted', 'metadata', 'summary',\n",
    "       'start_notes', 'end_notes', 'chapters', 'text', 'kudos', 'comments',\n",
    "       'bookmarks', 'hits'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fic_row_complete(row):\n",
    "    \"\"\"\n",
    "    Takes one row of a fic dtb.\n",
    "    Returns a Boolean on whether or not the given row is completely filled.\n",
    "    \"\"\"\n",
    "    new_row = row.copy().drop(columns=['dtb_type','date_last_viewed','cur_chapter', 'my_notes', 'metadata'])\n",
    "    return len(np.where(pd.isnull(new_row))[1]) == 0\n",
    "\n",
    "# is_fic_row_complete(ficDTB.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e06919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_fic_ao3_info(fic_id, session, report=False):\n",
    "    \"\"\"\n",
    "    Takes a fic id (int).\n",
    "    Returns a 1-row pandas DF populated by ao3 data from the given fic id.\n",
    "    \"\"\"\n",
    "    # initialize temp holder & fic obj\n",
    "    single_fic = pd.DataFrame({'id': [fic_id]})\n",
    "    fic = AO3.Work(fic_id, session=session)\n",
    "\n",
    "    # write report info & report    \n",
    "    title = fic.title\n",
    "    authors = json.dumps([author.username for author in fic.authors])\n",
    "    fandoms = json.dumps(fic.fandoms)\n",
    "\n",
    "    single_fic['title'] = title\n",
    "    single_fic['authors'] = authors\n",
    "    single_fic['fandoms'] = fandoms\n",
    "    if report: print(f\"- Wrote '{title}' by {authors}\\nin {fandoms}\")\n",
    "\n",
    "    # Write remaining info:\n",
    "    # metadata\n",
    "    single_fic['fic_obj'] = fic\n",
    "    single_fic['date_obj_updated'] = datetime.now()\n",
    "#     single_fic['metadata'] = json.dumps(fic.metadata)\n",
    "    single_fic['is_subscribed'] = fic.is_subscribed\n",
    "    single_fic['is_restricted'] = fic.restricted\n",
    "    \n",
    "    # tags\n",
    "    single_fic['rating'] = fic.rating\n",
    "    single_fic['categories'] = json.dumps(fic.categories)\n",
    "    single_fic['warnings'] = json.dumps(fic.warnings)\n",
    "    single_fic['relationships'] = json.dumps(fic.relationships)\n",
    "    single_fic['characters'] = json.dumps(fic.characters)\n",
    "    single_fic['tags'] = json.dumps(fic.tags)\n",
    "    single_fic['series'] = json.dumps([series.id for series in fic.series])\n",
    "    single_fic['collections'] = json.dumps(fic.categories)\n",
    "    \n",
    "    # text\n",
    "    single_fic['summary'] = fic.summary\n",
    "    single_fic['start_notes'] = fic.start_notes\n",
    "    single_fic['end_notes'] = fic.end_notes\n",
    "    single_fic['chapters'] = json.dumps([(chap.title, chap.id) for chap in fic.chapters])\n",
    "    single_fic['text'] = fic.text\n",
    "    \n",
    "    # stats\n",
    "    single_fic['words'] = fic.words\n",
    "    single_fic['kudos'] = fic.kudos\n",
    "    single_fic['comments'] = fic.comments\n",
    "    single_fic['bookmarks'] = fic.bookmarks\n",
    "    single_fic['hits'] = fic.hits\n",
    "    single_fic['nchapters'] = fic.nchapters\n",
    "    single_fic['expected_chapters'] = fic.expected_chapters\n",
    "    single_fic['complete'] = fic.complete\n",
    "    \n",
    "    # dates\n",
    "    single_fic['date_published'] = fic.date_published\n",
    "    \n",
    "    single_fic['date_updated'] = fic.date_updated\n",
    "    single_fic['date_edited'] = fic.date_edited\n",
    "    single_fic['language'] = fic.language\n",
    "\n",
    "    # not found\n",
    "    single_fic['not_found'] = False\n",
    "    \n",
    "    return single_fic\n",
    "\n",
    "# fill_fic_ao3_info(16616795, ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a95722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_fic_dtb(initial_fic_dtb, session, done_set, update=False, report=False):\n",
    "    \"\"\"\n",
    "    Takes a seriesDTB (pandas DataFrame, post series-0), an AO3 session, a Boolean to put in 'update' mode \n",
    "        (aka update all rows regardless of it they're already complete) and a Boolean to print report.\n",
    "    Modifies given seriesDTB by filling it up with ao3 information.\n",
    "    Returns nothing.\n",
    "    \"\"\"\n",
    "    # find total number of series to fill\n",
    "    total = max(initial_fic_dtb.index)\n",
    "    \n",
    "    # ensure initial_fic_dtb has all necessary columns\n",
    "    for col_name in fic_columns:\n",
    "        if col_name not in initial_fic_dtb.columns:\n",
    "            initial_fic_dtb[col_name] = np.nan\n",
    "        if 'date' in col_name:\n",
    "            initial_fic_dtb[col_name] = initial_fic_dtb[col_name].astype('datetime64[ns]')\n",
    "    \n",
    "    # find remaining indices\n",
    "    remaining_indices = set(initial_fic_dtb.index) ^ done_set\n",
    "    \n",
    "    # fill all fics/rows in initial_fic_dtb\n",
    "    for ind in remaining_indices: \n",
    "        try: \n",
    "            # when not using full-report, alert at every 100 series\n",
    "            if not report:\n",
    "                if ind%100 == 0: \n",
    "                    print(f'- {ind}! (printed every 100)')\n",
    "\n",
    "            # if fic/row not entirely filled in OR we're updating the dtb \n",
    "            if ind not in done_set and ((not is_fic_row_complete(initial_fic_dtb.iloc[[ind]])) or update):\n",
    "                # get fic id\n",
    "                fic_id = initial_fic_dtb.at[ind, \"id\"]\n",
    "                if report: print(f\"{ind}: [{(ind/total)*100:.2f}%] Filling for [{fic_id}]\")\n",
    "\n",
    "                # get ao3 info\n",
    "                fic_ao3_info = fill_fic_ao3_info(fic_id, session, report=False)\n",
    "\n",
    "                # update initial_fic_dtb with series_ao3_info (new info will overwrite old info)\n",
    "                fic_ao3_info.index = [ind]\n",
    "                initial_fic_dtb.update(fic_ao3_info, join='left', overwrite=True)\n",
    "                \n",
    "            # if series/row is satifactory\n",
    "            else: \n",
    "                if report: print(f\"{ind}: .\")\n",
    "                    \n",
    "            # add index to done set\n",
    "            done_set.add(ind)\n",
    "\n",
    "        # if something goes wrong \n",
    "        except Exception as e:\n",
    "            initial_fic_dtb.at[ind, \"not_found\"] = e\n",
    "            if e.args[0] == 'Cannot find work':\n",
    "                print(f\"-- ERROR [], {e}: {initial_fic_dtb.at[ind, 'id']}\")\n",
    "                done_set.add(ind) # add index to done set\n",
    "            elif er1.args[0] == \"'NoneType' object has no attribute 'text'\":\n",
    "                print(f\"-- ERROR, {e}: {initial_fic_dtb.at[ind, 'id']}\")\n",
    "                done_set.add(ind) # add index to done set\n",
    "#             else: \n",
    "#                 raise e\n",
    "        \n",
    "        # update temp csv w/ new row/series\n",
    "        if ind%20 == 0: \n",
    "            file_name = \"temp_fic.csv\"\n",
    "            if report: print(f'Wrote to {file_name}')\n",
    "            initial_fic_dtb.to_csv(file_name)\n",
    "        \n",
    "        \n",
    "\n",
    "    # Write finished series DTB to csv\n",
    "    initial_fic_dtb.to_csv(\"temp_fic_final.csv\")\n",
    "\n",
    "    print(\"\\nDONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0edabbc",
   "metadata": {},
   "source": [
    "<a id=\"sec2.2\"></a>\n",
    "### 2.2 Filling ficDTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33db36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1=my_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ficDTB = pd.read_csv('data-checkpoints/fic-3-all_02-03-23.csv', index_col=0, parse_dates=['date_obj_updated']) \\\n",
    "#             .drop(columns=['is_missing', 'restricted','notes'])\n",
    "\n",
    "# done_set= set()\n",
    "# AO3.utils.limit_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6115b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ficDTB.to_csv('fic5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5987f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = set()\n",
    "for ind in ficDTB.index:\n",
    "    e1 = ficDTB.at[ind,'not_found']\n",
    "    if type(e1) is not bool and type(e1) is not float and e1.args[0] == 'We are being rate-limited. Try again in a while or reduce the number of requests':\n",
    "        err.add(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c876268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fill_fic_dtb(ficDTB, ss1, done_set, update=False, report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80245d49",
   "metadata": {},
   "source": [
    "<a id=\"otherUrl_1\"></a>\n",
    "## 2. Adding other url-data fics to ficDTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab56c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most recent ficDTB file\n",
    "ficDTB = pd.read_csv(\n",
    "    \"data-checkpoints/fic-3-all_02-03-23.csv\",\n",
    "    parse_dates=[\"date_added\", \"date_last_viewed\"],\n",
    "    index_col=0,\n",
    ")\n",
    "ficDTB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f836b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most recent authors file\n",
    "userDTB = pd.read_csv(\n",
    "    \"data-checkpoints/users-0-all_02-26-23.csv\", parse_dates=[\"date_added\"], index_col=0\n",
    ")\n",
    "userDTB[\"location_found\"] = \"ao3\"\n",
    "userDTB.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983a5dd",
   "metadata": {},
   "source": [
    "<a id=\"otherUrl_1_1\"></a>\n",
    "### 2A. Adding Info from otherDTB\n",
    "- **2A.1)** Add fics to ficDTB from otherDTB (ffn.net fics & ao3 external fics)\n",
    "- **2A.2)** Add users to userDTB from otherDTB (ffn.net users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da18a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in most recent others file\n",
    "othersDTB = pd.read_csv(\n",
    "    \"data-checkpoints/others-0-all_01-03-23.csv\",\n",
    "    parse_dates=[\"date_added\", \"date_last_viewed\"],\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "# get AO3 external fics & FFN.net urls\n",
    "ffn_net_fics = othersDTB.query(\"url.str.contains('archiveofourown.org/') or \\\n",
    "                                url.str.contains('fanfiction.net/s/')\")\n",
    "\n",
    "# get ffn.net users\n",
    "ffn_net_users = othersDTB.query(\"url.str.contains('fanfiction.net/u/')\")\n",
    "\n",
    "# get remaining (all non-fanfiction.net & ao3 urls)\n",
    "remaining_others = othersDTB.query(\"~(url.str.contains('fanfiction.net/u/') or \\\n",
    "                                      url.str.contains('archiveofourown.org/') or \\\n",
    "                                      url.str.contains('fanfiction.net/s/'))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining_others.to_csv('data-checkpoints/others-1-all_03-09-23.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76e0ec",
   "metadata": {},
   "source": [
    "### CHECKPOINT! others-1-all_03-09-23.csv (remaining non-ffn.net and non-ao3 links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ab79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fic_url_type(url):\n",
    "    if 'archiveofourown.org/external_works/' in url: return 'ao3_external_work'\n",
    "    elif 'fanfiction.net/s/' in url: return 'work'\n",
    "    else: return np.nan\n",
    "    \n",
    "def get_location_found(url):\n",
    "    if 'archiveofourown.org/' in url: return 'ao3'\n",
    "    elif 'fanfiction.net/' in url: return 'ffn.net'\n",
    "    else: return np.nan\n",
    "    \n",
    "ffn_net_fics['location_found'] = ffn_net_fics['url'].apply(get_location_foound)\n",
    "ffn_net_fics['url_type'] = ffn_net_fics['url'].apply(get_fic_url_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58788a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new fic urls to ficDTB\n",
    "ficDTB = (\n",
    "    pd.concat([ficDTB, ffn_net_fics])\n",
    "    .reset_index()\n",
    "    .drop_duplicates(subset=[\"url\"])\n",
    "    .drop(columns=[\"index\"])\n",
    ")\n",
    "\n",
    "ficDTB.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de829331",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_net_users['location_found'] = ffn_net_users['url'].apply(get_location_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d27ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new user urls to usersDTB\n",
    "userDTB = (\n",
    "    pd.concat([userDTB, ffn_net_users])\n",
    "    .reset_index()\n",
    "    .drop_duplicates(subset=[\"url\"])\n",
    "    .drop(columns=[\"index\"])\n",
    ")\n",
    "\n",
    "userDTB.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea024bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2A.2) Add users to userDTB from otherDTB (ffn.net users)\n",
    "\n",
    "# get AO3 external fics & FFN.net urls\n",
    "new_users = othersDTB.query('url.str.contains(\"fanfiction.net/u/\")')\n",
    "\n",
    "# remove ffn.net fics & ao3 external works\n",
    "othersDTB = othersDTB.query('~(url.str.contains(\"fanfiction.net/u/\"))')\n",
    "\n",
    "# add new fic urls to ficDTB\n",
    "userDTB = (\n",
    "    pd.concat([userDTB, new_users])\n",
    "    .reset_index()\n",
    "    .drop_duplicates(subset=[\"url\"])\n",
    "    .drop(columns=[\"index\"])\n",
    ")\n",
    "\n",
    "userDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61599e",
   "metadata": {},
   "source": [
    "#### Other CHECKPOINT! others-1-all_02-07-23.csv (removed all fanfiction.net & ao3 (external) works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "othersDTB = othersDTB.reset_index(drop=True)\n",
    "# othersDTB.to_csv(\"data-checkpoints/others-1-all_02-07-23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0edd7aa",
   "metadata": {},
   "source": [
    "<a id=\"otherUrl_1_2\"></a>\n",
    "### 2B. Adding FFN.net fics & users\n",
    "- manually collected authors & fics from my 'Alerts' & 'Favorites' sections on fanfiction.net\n",
    "- made not distinction between the two categories, marked all fics as read\n",
    "    - if there were any duplicate authors or fics in both Alerts & Favorites, chose earliest add date\n",
    "    \n",
    "- **2B.1)** Add users to userDTB from ffn.net Alerts & Favorites\n",
    "- **2B.2)** Add fics to ficDTB from ffn.net Alerts & Favorites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828b5dc",
   "metadata": {},
   "source": [
    "### 2B.1) Add users to userDTB from ffn.net Alerts & Favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991380a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in authors from fanfiction.net account\n",
    "ffn_authors = pd.read_csv(\n",
    "    \"urlsOutput/ffn-net_authors_02-04-23.csv\", index_col=0, parse_dates=[\"date_added\"]\n",
    ")\n",
    "\n",
    "# add ffn_authors to userDTB\n",
    "userDTB = pd.concat([userDTB, ffn_authors]).reset_index().drop(columns=[\"index\"])\n",
    "userDTB.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e761a",
   "metadata": {},
   "source": [
    "#### User CHECKPOINT! users-1-all_02-07-23.csv (Add ffn.net users )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populateFicDTB(useAccount, debug=False):\n",
    "    \"\"\"\n",
    "    Takes boolean (use account/able to access restricted?)\n",
    "    Fills any empty row of FicDTB with: title, authors, fandoms, Work object, and date this all last updated\n",
    "    Requires that all rows' url_type & id be filled in.\n",
    "    Returns nothing.\n",
    "    \"\"\"\n",
    "    total = max(ficDTB.index)\n",
    "\n",
    "    for ind in ficDTB.index:\n",
    "        # get necessary info from DTB\n",
    "        title = ficDTB.at[ind, \"title\"]\n",
    "        authors = ficDTB.at[ind, \"authors\"]\n",
    "        fandoms = ficDTB.at[ind, \"fandoms\"]\n",
    "        fic_obj = ficDTB.at[ind, \"fic_obj\"]\n",
    "        obj_date = ficDTB.at[ind, \"date_obj_updated\"]\n",
    "        url_type = ficDTB.at[ind, \"url_type\"]\n",
    "\n",
    "        # if any col is empty\n",
    "        if (\n",
    "            pd.isnull(title)\n",
    "            or pd.isnull(authors)\n",
    "            or pd.isnull(fandoms)\n",
    "            or pd.isnull(fic_obj)\n",
    "            or pd.isnull(obj_date)\n",
    "        ):\n",
    "            try:\n",
    "                # get fic id\n",
    "                if url_type == \"chapters\":\n",
    "                    print(\"-- chapter!\")\n",
    "                    html_text = requests.get(url).text\n",
    "                    soup = BeautifulSoup(html_text, \"lxml\")\n",
    "                    wId = soup.find(\n",
    "                        \"input\", attrs={\"id\": \"kudo_commentable_id\", \"type\": \"hidden\"}\n",
    "                    )[\"value\"]\n",
    "                else:\n",
    "                    wId = ficDTB.at[ind, \"id\"]\n",
    "                print(f\"- [{(ind/total)*100:.2f}%, #{ind}] Filling for [{wId}]\")\n",
    "\n",
    "                # initialize Work obj\n",
    "                if useAccount:\n",
    "                    work = AO3.Work(wId, session=session)\n",
    "                else:\n",
    "                    work = AO3.Work(wId)\n",
    "\n",
    "                # write new info into DTB\n",
    "                newTitle = work.title\n",
    "                ficDTB.at[ind, \"title\"] = newTitle\n",
    "                if debug:\n",
    "                    print(f\"- Wrote '{newTitle}'\")\n",
    "\n",
    "                newAuthors = json.dumps([x.username for x in work.authors])\n",
    "                ficDTB.at[ind, \"authors\"] = newAuthors\n",
    "                if debug:\n",
    "                    print(f\"- Wrote '{newAuthors}'\")\n",
    "\n",
    "                newFandoms = json.dumps(work.fandoms)\n",
    "                ficDTB.at[ind, \"fandoms\"] = newFandoms\n",
    "                if debug:\n",
    "                    print(f\"- Wrote '{newFandoms}'\")\n",
    "\n",
    "                ficDTB.at[ind, \"fic_obj\"] = work\n",
    "                now = datetime.now()\n",
    "                ficDTB.at[ind, \"date_obj_updated\"] = now\n",
    "                if debug:\n",
    "                    print(f\"- Wrote fic obj at: {now.strftime('%m-%d-%y %H:%M:%S')}\")\n",
    "\n",
    "            # if Error\n",
    "            except Exception as e:\n",
    "                print(f\"-- ERROR: {repr(e)} - - - {ficDTB.at[ind, 'id']}\")\n",
    "        else:\n",
    "            print(\".\")\n",
    "\n",
    "    print(\"\\nDONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "userDTB = userDTB.reset_index(drop=True)\n",
    "# userDTB.to_csv(\"data-checkpoints/users-1-all_02-07-23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f8787",
   "metadata": {},
   "source": [
    "### 2B.2) Add fics to ficDTB from ffn.net Alerts & Favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be590e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in fics from fanfiction.net account\n",
    "ffn_fics = pd.read_csv(\n",
    "    \"urlsOutput/ffn-net_fics_02-04-23.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=[\"date_added\", \"date_updated\"],\n",
    ")\n",
    "\n",
    "def temp(x):\n",
    "    return json.dumps([x.strip() for x in x.split(\",\")])\n",
    "\n",
    "ffn_fics[\"authors\"] = ffn_fics[\"author\"].apply(temp)\n",
    "ffn_fics[\"fandoms\"] = ffn_fics[\"fandoms\"].apply(temp)\n",
    "ffn_fics = ffn_fics.drop(columns=[\"author\"])\n",
    "\n",
    "# add ffn_fics to ficDTB\n",
    "ficDTB = pd.concat([ficDTB, ffn_fics]).reset_index(drop=True)\n",
    "ficDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2984124",
   "metadata": {},
   "source": [
    "#### Fic CHECKPOINT! fics-4-all_02-07-23.csv (Add fics from ffn.net from ffn.net account & othersDTB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49e0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ficDTB.to_csv(\"data-checkpoints/fics-4-all_02-07-23.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c75d802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"raw_data_for_v9.xlsx\", sheet_name=None)\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa860d9",
   "metadata": {},
   "source": [
    "<a id=\"otherUrl_1_3\"></a>\n",
    "### 2.3 Adding AO3 fics\n",
    "- make DTB of all AO3 fic-bookmarks, fic-subs, user-subs, series-subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4136711",
   "metadata": {},
   "outputs": [],
   "source": [
    "ficDTB.smk_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80e259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ficDTB = pd.read_csv('data-checkpoints/fics-4-all_02-07-23.csv', index_col=0)\n",
    "ficDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a42416",
   "metadata": {},
   "source": [
    "<a id=\"TAG\"></a>\n",
    "## Random Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd4c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill new info cols\n",
    "# populateFicDTB(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24243210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRating(x):\n",
    "    if pd.isnull(x):\n",
    "        return x\n",
    "\n",
    "    rating = x.rating\n",
    "    if rating == \"Teen And Up Audiences\t\":\n",
    "        return \"T\"\n",
    "    elif rating == \"Explicit\":\n",
    "        return \"E\"\n",
    "    elif rating == \"Mature\":\n",
    "        return \"M\"\n",
    "    elif rating == \"General Audiences\":\n",
    "        return \"G\"\n",
    "    elif rating == \"Not Rated\":\n",
    "        return \"--\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0614bb1",
   "metadata": {},
   "source": [
    "## **start making search/matching functions for text, ffn.net, version matching**\n",
    "- match by title:\n",
    "    - get title of unknown fic\n",
    "    - search ficDTB for matching titles\n",
    "        - if no match: add col to ficDTB with as much into as possible\n",
    "        - if match: update row with incoming data (version, smk_source, dtb_type, date_added) \n",
    "        \n",
    "\n",
    "- OVERALL SECTION\n",
    "    - read json file containing up unsorted txt fics\n",
    "    - match them one by one \n",
    "    - remove url as matched\n",
    "    - when done, overwrite previous file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debcc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_default_dates = {\n",
    "    1: \"05-31-2017 00:00:01\",\n",
    "    2: \"05-30-2018 00:00:01\",\n",
    "    3: \"08-09-2018 00:00:01\",\n",
    "    4: \"08-25-2018 00:00:01\",\n",
    "    5: \"01-01-2019 00:00:01\",\n",
    "    6: \"04-09-2020 00:00:01\",\n",
    "    7: \"05-01-2021 00:00:01\",\n",
    "    8: \"06-04-2022 00:00:01\",\n",
    "    9: \"10-24-2022 00:00:01\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early.reset_index(drop=True).to_csv(\"urlsOutput/v1-6_txt/all_early.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933386a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_titles = [x.lower() for x in ficDTB_titles]\n",
    "early_tit = [x.lower() for x in early_titles]\n",
    "\n",
    "for ind in early.index:\n",
    "    title = early.at[ind, \"title\"].lower()\n",
    "    if title in fic_titles:\n",
    "        early = early.drop(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_fics = pd.DataFrame(columns=early.columns.to_list())\n",
    "txt_fics[\"date_added\"] = pd.to_datetime(txt_fics[\"date_added\"])\n",
    "\n",
    "txt_fics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc195406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all_early CSV\n",
    "early = pd.read_csv(\n",
    "    \"urlsOutput/v1-6_txt/all_early.csv\", index_col=0, parse_dates=[\"date_added\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "early_titles = early.query(\"work_type == 'fic'\").title.to_list()\n",
    "ficDTB_titles = ficDTB.loc[pd.isnull(ficDTB[\"title\"]) == False].title.to_list()\n",
    "\n",
    "for ind in early.index:\n",
    "    title = str(early.at[ind, \"title\"])\n",
    "\n",
    "    #     from_early = difflib.get_close_matches(title, early_titles, n=5, cutoff=0.6)\n",
    "    #     if title in from_early: from_early.remove(title)\n",
    "\n",
    "    from_dtb = difflib.get_close_matches(title, ficDTB_titles, n=3, cutoff=0.6)\n",
    "\n",
    "    if len(from_dtb) == 0:\n",
    "        # add text fic to ficDTB\n",
    "        txt_fics = pd.concat([txt_fics, early.iloc[[ind]]])\n",
    "\n",
    "    print(f\"NEW: {title}\")\n",
    "    [print(f\"- {x}\") for x in from_dtb]\n",
    "    #     if len(from_early) > 0: print(f'--- {from_early}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48faf92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# t1 = pd.read_excel('testing_data/raw_data_for_v9.xlsx', sheet_name='fandom_names')\n",
    "# fandom_names = pd.read_csv(\"testing_data/fandom_names.csv\")\n",
    "v6_fic_text_ffn = pd.read_excel('testing_data/raw_data_for_v9.xlsx', sheet_name=\"v6_fic_text_ffn-dtb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b140f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FANDOM_NAMES = {('1/2 prince'): '1/2_prince',\n",
    "                ('avatar-'): 'avatar',\n",
    "                ('attack on titan'): 'attack on titan',\n",
    "               (\"assassin's creed\"): 'assassins_creed',\n",
    "               ('avatar: the last airbender'): 'atla',\n",
    "               ('miraculous ladybug'): 'miraculous_ladybug',\n",
    "               ('big hero 6', 'bh6'): 'big_hero_6',\n",
    "               ('black panther'): 'black_panther',\n",
    "               ('katekyo hitman reborn', 'khr'): 'katekyo_hitman_reborn',\n",
    "               ('books of the raksura'): 'books_of_the_raksura',\n",
    "                ('brooklyn nine-nine', 'b99'): 'brooklyn_99',\n",
    "                ('captain america'): 'captain_america',\n",
    "                ('captive prince'): 'captive_prince',\n",
    "                ('chronicles of narnia'): 'chronicles_of_narnia',\n",
    "                ('code geass'): 'code_geass',\n",
    "                ('criminal minds'): 'criminal_minds',\n",
    "                ('danny phantom'): 'danny_phantom',\n",
    "                ('dark angel'): 'dark angel',\n",
    "                ('detroit: become human'): 'detroit_become_human',\n",
    "                ('disney', 'greek & roman myths',\n",
    "                    'beauty & the beast',\n",
    "                    'robin hood', 'rapunzel',\n",
    "                    'pocahontas','sleeping beauty',\n",
    "                    'the little mermaid','the secret garden',\n",
    "                    'aladdin','cinderella','maid maleen',\n",
    "                    'mulan'): 'folklore',\n",
    "                ('eyeshield 21'): 'eyeshield_21',\n",
    "                ('fairy tail'): 'fairy_tail',\n",
    "                ('x-men'): 'xmen',\n",
    "                ('fast & furious'): 'fast&furious',\n",
    "                ('final fantasy vii'): 'final_fantasy_vii',\n",
    "                ('final fantasy viii'): 'final_fantasy_viii',\n",
    "                ('final fantasy xv'): 'final_fantasy_xv',\n",
    "                ('fullmetal alchemist'): 'fullmental_alchemist',\n",
    "                ('game of thrones', 'got'): 'game_of_thrones',\n",
    "                ('good omens'): 'good_omens',\n",
    "                ('gravity falls'): 'gravity_falls',\n",
    "                ('guardians of the galaxy','gotg'): 'guardians_of_the_galaxy',\n",
    "                ('gundam wing/ac'): 'gundam_wing/ac',\n",
    "                ('john wick'): 'john_wick',\n",
    "                ('joy of life'): 'joy_of_life',\n",
    "                ('harry potter', \"hp\"): 'harry_potter',\n",
    "                ('highschool of the dead'): 'highschool_of_the_dead',\n",
    "                ('how to train your dragon'): 'httyd',\n",
    "                ('hunger games'): 'hunger_games',\n",
    "                ('james bond'): 'james_bond',\n",
    "                ('jurassic park'): 'jurassic_park',\n",
    "                ('k anime'): 'k_anime',\n",
    "                ('kingsmen'): 'kingsman',\n",
    "                ('kuroko no basuke', 'knb'): 'kuroko_no_basuke',\n",
    "                ('kung fu panda'): 'kung_fu_panda',\n",
    "                ('lotr'): 'lord_of_the_rings',\n",
    "                ('ouran high school host club', 'ohshc'): 'ouran_hshc',\n",
    "                ('gdc','modao zushi'): 'mdzs',\n",
    "                ('magi!!! labyrinth of magic'): 'magi_lom',\n",
    "                ('miraculous ladybug'): 'miraculous_ladybug',\n",
    "                ('monster hunter'): 'monster_hunter',\n",
    "                ('moon knight'): 'moon_knight',\n",
    "                ('one piece'): 'one_piece',\n",
    "                ('pacific rim'): 'pacific_rim',\n",
    "                ('percy jackson and the olympians'): 'percy_jackson_olympians',\n",
    "                ('person of interest'): 'person_of_interest',\n",
    "                ('phineas and ferb'): 'phineas_and_ferb',\n",
    "                ('pkmn: sword and shield'): 'pkmn_sword&shield',\n",
    "                ('pokémon','pkmn'): 'pokemon',\n",
    "                ('prince of tennis'): 'prince_of_tennis',\n",
    "                ('princess kaguya'): 'princess_kaguya',\n",
    "                ('reincarnated as a sword'): 'reincarnated_as_a_sword',\n",
    "                ('rise of the guardians'): 'rise_of_the_guardians',\n",
    "                ('solo levelling'): 'solo_levelling',\n",
    "                ('star wars','sw'): '1234SW',\n",
    "                ('star wars: the clone wars','star wars: clone wars',\n",
    "                     'star wars cw','sw: the clone wars'): 'star_wars_cw',\n",
    "                ('stargate-'): 'stargate',\n",
    "                ('stargate atlantis'): 'stargate_atlantis',\n",
    "                ('spn'): 'supernatural',\n",
    "                ('stranger things'): 'stranger_things',\n",
    "                ('scum villain', \"scum villain's self-saving system\"): 'svsss',\n",
    "                ('sword art online'): 'sword_art_online',\n",
    "                ('teen wolf'): 'teen_wolf',\n",
    "                ('the 100'): 'the_100',\n",
    "                ('the croods'): 'the_croods',\n",
    "                ('the flash'): 'the_flash',\n",
    "                ('the hobbit'): 'the_hobbit',\n",
    "                ('the last of us'): 'the_last_of_us',\n",
    "                ('the song of achillles'): 'the_song_of_achillles',\n",
    "                ('the witcher'): 'the_witcher',\n",
    "                ('tiger & bunny'): 'tiger&bunny',\n",
    "                ('tokyo ghoul'): 'tokyo_ghoul',\n",
    "                ('umbrella academy'): 'umbrella_academy',\n",
    "                ('vampire hunter d'): 'vampire_hunter_d',\n",
    "                ('yona of the dawn'): 'yona_of_the_dawn',\n",
    "                ('young hercules'): 'young_hercules',\n",
    "                ('young justice'): 'young_justice',\n",
    "                ('yuuri on ice', 'yoi','yuuri on ice!!!'): 'yuuri_on_ice',\n",
    "                ('gotham'): 'gotham',\n",
    "                ('daredevil'): 'daredevil',\n",
    "                ('temeraire'): 'temeraire',\n",
    "                ('transformers'): 'transformers',\n",
    "                ('leverage'): 'leverage',\n",
    "                ('hamilton'): 'hamilton',\n",
    "                ('fbawtft', 'fantastic beasts and where to find them'): 'fbawtft',\n",
    "                ('spiderman'): 'spiderman',\n",
    "                ('avengers'): 'avengers',\n",
    "                ('smallville'): 'smallville',\n",
    "                ('twilight'): 'twilight',\n",
    "                ('thor'): 'thor',\n",
    "                ('arrow'): 'arrow',\n",
    "                ('ncis'): 'ncis',\n",
    "                ('naruto'): 'naruto',\n",
    "                ('merlin'): 'merlin',\n",
    "                ('travelers'): 'travelers',\n",
    "                ('left4dead'): 'left4dead',\n",
    "                ('megamind'): 'megamind',\n",
    "                ('rwby'): 'rwby',\n",
    "                ('minecraft'): 'minecraft',\n",
    "                ('original'): 'original_work',\n",
    "                ('bts'): 'bts',\n",
    "                ('bleach'): 'bleach',\n",
    "                ('batman'): 'batman',\n",
    "                ('torchwood'): 'torchwood',\n",
    "                ('sherlock'): 'sherlock',\n",
    "                ('descendants 2015'): 'descendants',\n",
    "                ('bnha', 'mha','boku no hero academia'): 'bnha',\n",
    "                ('multiple'): 'multiple_fandoms',\n",
    "               }\n",
    "\n",
    "\n",
    "# def get_clean_fandom_name(unclean_fandom_name) -> str:\n",
    "#     \"\"\"\n",
    "#     Takes str unclean fandom name.\n",
    "#     Returns str clean fandom name (if found), else returns None.\n",
    "#     \"\"\"\n",
    "#     # if it's already a clean fandom\n",
    "#     if unclean_fandom_name in FANDOM_NAMES.values():\n",
    "#         return unclean_fandom_name\n",
    "    \n",
    "#     # else, search thru all aliases\n",
    "#     for key in FANDOM_NAMES.keys():\n",
    "#         if unclean_fandom_name in key:\n",
    "#             return FANDOM_NAMES[key]\n",
    "\n",
    "\n",
    "def fandom_report(dtb, fic_col, verbose=False) -> int:\n",
    "    \"\"\"\n",
    "    TAKES a dtb - read from csv/xlsx\n",
    "        str - column name of the fandoms\n",
    "        boolean - print report\n",
    "    PURPOSE: Check all fandoms in 'fic_col'. If verbose, print a report: \n",
    "        num rows, known fandoms, & unknown fandoms\n",
    "        list of error index nums\n",
    "        list of unknown fandoms\n",
    "    RETURNS 1 if no unknown fandoms & no errors, 0 otherwise\n",
    "    \"\"\"\n",
    "    known_fandoms = []\n",
    "    unknown_fandoms = []\n",
    "    clean_fandoms = []\n",
    "    error_ind = set()\n",
    "    num_rows = len(dtb)\n",
    "    \n",
    "    # for each fandom row\n",
    "    for ind in dtb.index:\n",
    "        fandom_str = dtb.loc[ind].loc[fic_col]\n",
    "        \n",
    "        # if fandom cell empty\n",
    "        if pd.isnull(fandom_str):\n",
    "            error_ind.add(ind)\n",
    "            continue\n",
    "        \n",
    "        # clean fandom string\n",
    "        fandom_list = fandom_str.replace('*','') \\\n",
    "                            .replace(' x ',',') \\\n",
    "                            .split(',')\n",
    "        \n",
    "        # for each fandom in fic\n",
    "        for old_fandom in fandom_list:\n",
    "            \n",
    "            # get clean fandom\n",
    "            if old_fandom in FANDOM_NAMES.values():\n",
    "                clean_fandoms.append(old_fandom)\n",
    "                clean_fandom = old_fandom\n",
    "            else:\n",
    "                clean_fandom = get_clean_fandom_name(old_fandom)\n",
    "            \n",
    "            # if no clean fandom found\n",
    "            if not clean_fandom:\n",
    "                unknown_fandoms.append((ind, old_fandom))\n",
    "            else:\n",
    "                known_fandoms.append(clean_fandom)\n",
    "    \n",
    "    # print report\n",
    "    unknown_fandom_names = []\n",
    "    if unknown_fandoms:\n",
    "        unknown_fandom_names = list(zip(*unknown_fandoms))[1]\n",
    "    \n",
    "    num_unclean = len(set(known_fandoms))-len(set(clean_fandoms))\n",
    "    if verbose:\n",
    "        print(f'- --- FANDOM REPORT --- -')\n",
    "        print(f'- # rows/fandoms:           {num_rows}')\n",
    "        print(f'- # errors (row num):       {len(error_ind)}')\n",
    "        [print('  ', err) for err in error_ind]\n",
    "        print(f'- # unique known fandoms:   {len(set(known_fandoms))} (total), \\\n",
    "            {len(set(clean_fandoms))} (clean), {num_unclean} (unclean)')\n",
    "        print(f'- # unique unknown fandoms: {len(set(unknown_fandom_names))}')\n",
    "        [print('  ', fname) for fname in set(unknown_fandom_names)]\n",
    "\n",
    "    if len(error_ind) == 0 and len(set(unknown_fandom_names)) == 0:\n",
    "        if num_unclean == 0:\n",
    "            return f\"Ideal - all fandoms known & clean\"\n",
    "        return f\"Good - all fandoms known, but {num_unclean} unclean\"\n",
    "    return f\"Bad - {len(error_ind)} errors and {len(set(unknown_fandom_names))} unknown fandoms\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02eafc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fandom_report(v6_fic_text_ffn, 'fic_fandom', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b7ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\".join(['1','2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46077e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_test = pd.read_csv(\"testing_data/v6_test_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d327c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fandom_names(dtb, fandom_col_name, verbose=False):\n",
    "    \"\"\"\n",
    "    Takes a dtb and str name of the fandom column.\n",
    "    Reads the fandoms in the given dtb -> changes all fandom names to be consistent to the ones in FANDOM_NAMES.\n",
    "    Returns str status update.\n",
    "    \"\"\"\n",
    "    for ind in dtb.index:\n",
    "        # get & clean fandom string\n",
    "        fandom_str = dtb.at[ind, fandom_col_name]\n",
    "        fandom_list = fandom_str.replace('*','') \\\n",
    "                            .replace(' x ',',') \\\n",
    "                            .split(',')\n",
    "        \n",
    "        # for each fandom in fic\n",
    "        clean_fandoms = []\n",
    "        for old_fandom in fandom_list:\n",
    "            clean_fandom = get_clean_fandom_name(old_fandom)\n",
    "            clean_fandoms.append(clean_fandom)\n",
    "        \n",
    "        res = \",\".join(clean_fandoms)\n",
    "        print(res)\n",
    "#         # place clean string back into dtb\n",
    "#         dtb.at[ind, fandom_col_name]\n",
    "\n",
    "clean_fandom_names(v6_test, 'fic_fandom', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d133367",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cell = v6_test.at[5,'fic_fandom']\n",
    "test_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8308d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_test.at[5,'fic_fandom'] = 'assassins_creed,star_wars_cw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e49df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v6_test.to_csv('testing_data/v6_test_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e738f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = pd.read_excel(\"testing_data/raw_data_for_v9.xlsx\", sheet_name=\"v3_fic_text_fandom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc025b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
