{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5738ad9a",
   "metadata": {},
   "source": [
    "# Making Databases from Previous Versions' Data\n",
    "- <b>Name:</b> Sofia Kobayashi\n",
    "- <b>Date:</b> 01/02/2023\n",
    "- <b>Notebook Stage:</b> 1.0 (initial data collection & cleaning), finished\n",
    "- <b>Description:</b> Collecting all the data stored in all previous versions (v9.1 and below), and trying to collate all data, sort by work type & make into databases\n",
    "    - ONLY url data added here, much text data will be added in future notebooks\n",
    "\n",
    "### **<u>Table of Contents</u>**\n",
    "\n",
    "1. **[Imports](#imports)**\n",
    "1. **[Load in ALL urls](#load_urls)**\n",
    "    - All urls up until 01/13/2023\n",
    "1. **[Create 4 (sources) Database](#4_dtb)**\n",
    "    - v7_sheets, v8_old_local_files, pre (urls collected before 1/13/23), cur (urls collected on 1/13/23)\n",
    "    - cols: url, dtb_type, date_added, date_last_viewed, smk_source\n",
    "1. **[Combine 4 (sources) DTBs -> 1 big DTB (of all URLs)](#4_to_1_dtb)**\n",
    "1. **[Adding/filling metadata cols](#m1)**\n",
    "    - filled date_added, added version num\n",
    "1. **[Seperate AO3 works vs Others](#seperate_others)**\n",
    "    - **Others CHECKPOINT 0** - all non-AO3 urls & AO3 external works\n",
    "1. **[Label AO3 URLs & Separate into (work) DTBs](#seperate_ao3_dtbs)**\n",
    "1. **[Clean up & customize the new 7 databases](#clean_7)**\n",
    "    - 7 DTBs: collections, comments, search, series, tags, users, works\n",
    "    - **Col, Comments, Search, Tags, Users CHECKPOINTS 0** - in 'data-checkpoints' folder\n",
    "1. **[Fill seriesDTB](#fill_series)**\n",
    "    - **Series CHECKPOINT 1** - all series urls (as of 1/13/23) w/ basic meta data, de-dupped\n",
    "        - did not add text-data series\n",
    "1. **[Clean & prepare ficDTB](#fill_fics)**\n",
    "    - [**Fic CHECKPOINT 1**](#fill_fics_1) - *all* fic urls w/ basic metadata\n",
    "        - Cols: dtb_type, smk_source, version, date_added, date_last_viewed, url_type, id, url, col_work\n",
    "    - [**Fic CHECKPOINT 2**](#fill_fics_2) - fic urls fic-de-dupped (no fic info)\n",
    "        - Added cols: url_psueds, cur_chapter, notes\n",
    "    - [**Fic CHECKPOINT 3**](#fill_fics_3) - reorganized cols, added more, prepared for adding fic info (no fic info)\n",
    "        - Added cols: dtb_type, smk_source, version\tdate_added\tdate_last_viewed\turl_type\tid\turl\tcol_work\turl_psueds\tcur_chapter\tnotes\ttitle\tauthors\tfandoms\tfic_obj\tdate_obj_updated\n",
    "        - PLUS all other metadata that could be added by AO3 API\n",
    "        - did not all text-data fics, only url-data fics--text data fics to be added in next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd1de3",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "908ed844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "%run helpers.ipynb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "cur_date = datetime.now().strftime('%m-%d-%y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea591bd4",
   "metadata": {},
   "source": [
    "<a id=\"load_urls\"></a>\n",
    "\n",
    "## 2. Load in ALL urls (up until 01/13/23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8414b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all urls from v7\n",
    "with open(\"urlsOutput/v7_json/v7_authors.json\", \"r\") as infile:\n",
    "    v7_authors = json.load(infile) \n",
    "    \n",
    "with open(\"urlsOutput/v7_json/v7_lookInto.json\", \"r\") as infile:\n",
    "    v7_lookInto = json.load(infile)  \n",
    "    \n",
    "with open(\"urlsOutput/v7_json/v7_others.json\", \"r\") as infile:\n",
    "    v7_others = json.load(infile) \n",
    "    \n",
    "with open(\"urlsOutput/v7_json/v7_readUrls.json\", \"r\") as infile:\n",
    "    v7_read = json.load(infile) \n",
    "    \n",
    "with open(\"urlsOutput/v7_json/v7_toReadUrls.json\", \"r\") as infile:\n",
    "    v7_toRead = json.load(infile) \n",
    "    \n",
    "with open(\"urlsOutput/v7_json/v7_unsortedUrls.json\", \"r\") as infile:\n",
    "    v7_unsorted = json.load(infile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d12b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"urlsOutput/chrome_1.json\", \"r\") as infile:\n",
    "    chrome = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all urls collected BEFORE 1/13/23\n",
    "# with open(\"urlsOutput/oldUrls_01-13-23.json\", \"r\") as infile:\n",
    "#     pre = json.load(infile) \n",
    "#     pre = pd.DataFrame(pre).drop_duplicates(subset=[0])[0].to_list() # de-dup pre list\n",
    "\n",
    "with open(\"urlsOutput/pre.json\", \"r\") as infile:\n",
    "    pre = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all urls collected on 1/13/23\n",
    "with open(\"urlsOutput/readinglist_01-13-23.json\", \"r\") as infile:\n",
    "    cur = json.load(infile) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbae557",
   "metadata": {},
   "source": [
    "<a id=\"4_dtb\"></a>\n",
    "## 3. Create 4 databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18aad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDatetime(x):\n",
    "    if x is None: return x\n",
    "    else: return datetime.strptime(x, '%m-%d-%y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be022fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCur = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cur df - dates added, filter SECOND\n",
    "from datetime import datetime\n",
    "\n",
    "# load in cur\n",
    "dfCur = pd.DataFrame(cur)\n",
    "\n",
    "# convert dates\n",
    "dfCur[\"date_added\"] = dfCur[\"dateAdded\"].apply(toDatetime)\n",
    "dfCur[\"date_last_viewed\"] = dfCur[\"dateLastViewed\"].apply(toDatetime)\n",
    "dfCur[\"smk_source\"] = \"safari\"\n",
    "dfCur[\"dtb_type\"] = np.nan\n",
    "\n",
    "# sort by date added\n",
    "dfCur = dfCur.sort_values(by=[\"date_added\"]).drop(columns=[\"dateAdded\",\"dateLastViewed\"])\n",
    "\n",
    "# drop url duplicates (keep url added first)\n",
    "dfCur = dfCur.drop_duplicates(subset=[\"url\"], keep='first')\n",
    "\n",
    "dfCur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pre df\n",
    "dfPre = pd.DataFrame(pre).rename(columns={0:\"url\"})\n",
    "dfPre[\"date_added\"] = np.datetime64(\"NaT\")\n",
    "dfPre[\"date_last_viewed\"] = np.datetime64(\"NaT\")\n",
    "dfPre[\"dtb_type\"] = np.nan\n",
    "dfPre[\"smk_source\"] = \"v8_local_url_files\"\n",
    "\n",
    "dfPre = dfPre.drop_duplicates(subset=[\"url\"])\n",
    "\n",
    "dfPre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicDF(myList, dtb_type, dateAdded=np.datetime64(\"NaT\"), dateLastViewed=np.datetime64(\"NaT\"), source=\"v7_sheets\"):\n",
    "    \"\"\"\n",
    "    Takes a list -> DF, adds dtb_type, date_added & date_last_viewed, de-dups\n",
    "    \"\"\"\n",
    "    dfTemp = pd.DataFrame(myList).rename(columns={0:\"url\"}) # read in list\n",
    "    \n",
    "    # add cols\n",
    "    dfTemp[\"dtb_type\"] = dtb_type\n",
    "    dfTemp[\"date_added\"] = dateAdded\n",
    "    dfTemp[\"date_last_viewed\"] = dateLastViewed\n",
    "    dfTemp[\"smk_source\"] = source\n",
    "    \n",
    "    # de-dup\n",
    "    dfTemp = dfTemp.drop_duplicates(subset=[\"url\"])\n",
    "\n",
    "    return dfTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd81e1",
   "metadata": {},
   "source": [
    " - 01/01/2022 is default date for all v7 stuff\n",
    " \n",
    " - priortize v7 if date is NOT 01-01-22 00:00:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines v7 df - filter FIRST, date_added = ~v8 date\n",
    "date1 = datetime.strptime(\"01-01-22 00:00:01\", '%m-%d-%y %H:%M:%S')\n",
    "\n",
    "df_authors = basicDF(v7_authors, \"author\", date1)\n",
    "df_lookInto = basicDF(v7_lookInto, \"look_into\", date1)\n",
    "df_read = basicDF(v7_read, \"read\", date1)\n",
    "df_toRead = basicDF(v7_toRead, \"to_read\", date1)\n",
    "df_unsorted = basicDF(v7_unsorted, np.nan, date1)\n",
    "\n",
    "# combines all v7 dfs\n",
    "v7_df = pd.concat([df_authors, df_read, df_toRead, df_lookInto, df_unsorted]) # in order of priority, first kept\n",
    "v7_df = v7_df.drop_duplicates(subset=[\"url\"])\n",
    "\n",
    "v7_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a48ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define chrome df - no dates\n",
    "dfChrome = pd.DataFrame(chrome).rename(columns={0:\"url\"})\n",
    "dfChrome[\"date_added\"] = np.datetime64(\"NaT\")\n",
    "dfChrome[\"date_last_viewed\"] = np.datetime64(\"NaT\")\n",
    "dfChrome[\"dtb_type\"] = np.nan\n",
    "dfChrome[\"smk_source\"] = \"chrome\"\n",
    "\n",
    "dfChrome = dfChrome.drop_duplicates(subset=[\"url\"])\n",
    "\n",
    "dfChrome.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa55743",
   "metadata": {},
   "source": [
    "### DATABASE\n",
    "1. url - url\n",
    "1. date_added - closet guess to when it was added, either from safari reading list data or version guess\n",
    "    - v9 - 10-24-2022 00:00:01\n",
    "    - v8 - 06-04-2022 00:00:01\n",
    "    - v7 - 05/01/2021 00:00:01\n",
    "1. date_last_viewed - date\n",
    "    - only from safari reading list data\n",
    "1. dtb_type - dtb type\n",
    "    - read, toRead, lookInto, other, authors, NaN (unsorted)\n",
    "1. smk_source - where I found url/where v9.2 is pulling it from\n",
    "    - v8_local_url_files\n",
    "    - v7_sheets\n",
    "    - safari\n",
    "    - chrome\n",
    "    - txt_fic (not added yet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c6055",
   "metadata": {},
   "source": [
    "<a id=\"4_to_1_dtb\"></a>\n",
    "## 4. Combine all 4 -> 1 (not added v1-6 dates)\n",
    "- order: dfPre, dfChrome, dfCur, v7_df\n",
    "    - dfPre + dfChrome, update (only urls will be concat'd)\n",
    "    - +dfCur (add urls, overwrite with dateAdded & dateLastViewed)\n",
    "    - rename v7_df.date_added -> v7_date_added\n",
    "    - rename total.date_added -> cur_date_added\n",
    "    - +v7_df (add urls, overwrite dtb_type, leaves dateLastViewed alone)\n",
    "    - compare v7_date_added vs cur_date_added -> keep earliest one\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8876883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfPre + dfChrome\n",
    "total = new_combine(dfPre, dfChrome)\n",
    "total.smk_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d04b5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# +dfCur\n",
    "total = new_combine(total, dfCur)\n",
    "total.smk_source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc7a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename v7 & total's date_added\n",
    "total = total.rename(columns={\"date_added\": \"cur_date_added\"})\n",
    "v7_df = v7_df.rename(columns={\"date_added\": \"v7_date_added\"})\n",
    "total = new_combine(total, v7_df)\n",
    "total.smk_source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734452e",
   "metadata": {},
   "source": [
    "<a id='m1'></a>\n",
    "## 5. Combined!  Now add/fill metadata cols:\n",
    "- fill date_added\n",
    "- add version nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de8c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create total.date_added from the earliest date from 'cur_date_added' vs 'v7_date_added'\n",
    "total[\"date_added\"] = np.datetime64(\"NaT\")\n",
    "\n",
    "for ind in total.index:\n",
    "    v7 = total.at[ind, \"v7_date_added\"]\n",
    "    cur = total.at[ind, \"cur_date_added\"]\n",
    "    newDate = np.datetime64(\"NaT\")\n",
    "    if pd.isnull(v7) and pd.isnull(cur): newDate= np.datetime64(\"NaT\")\n",
    "    elif not pd.isnull(v7) and not pd.isnull(cur): newDate= min([v7,cur])\n",
    "    elif not pd.isnull(v7): newDate= v7\n",
    "    else: newDate= cur\n",
    "    \n",
    "    total.at[ind, \"date_added\"] = newDate\n",
    "\n",
    "total_2 = total.drop(columns=[\"v7_date_added\",\"cur_date_added\"])\n",
    "total_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff66ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all version nums (based on smk_source) (not added v1-6 or text fics)\n",
    "total_2[\"version\"] = 7\n",
    "\n",
    "for ind in total_2.index:\n",
    "    source = total_2.at[ind, \"smk_source\"]\n",
    "    verNum = 7\n",
    "    \n",
    "    if source == \"v8_local_url_files\": verNum = 8\n",
    "    elif source == \"safari\" or source == \"chrome\": verNum = 9\n",
    "    \n",
    "    total_2.at[ind, \"version\"] = verNum\n",
    "    \n",
    "total_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9145bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add date_added (by version number) for all non-date entities\n",
    "# v9 - 10-24-2022 00:00:01\n",
    "# v8 - 06-04-2022 00:00:01\n",
    "# v7 - 05/01/2021 00:00:01\n",
    "\n",
    "v9_date = datetime.strptime(\"10-24-22 00:00:01\", '%m-%d-%y %H:%M:%S')\n",
    "v8_date = datetime.strptime(\"06-04-22 00:00:01\", '%m-%d-%y %H:%M:%S')\n",
    "v7_date = datetime.strptime(\"05-01-21 00:00:01\", '%m-%d-%y %H:%M:%S')\n",
    "\n",
    "for ind in total_2.index:\n",
    "    added = total_2.at[ind, \"date_added\"]\n",
    "    if pd.isnull(added):\n",
    "        new_date = 0\n",
    "        source = total_2.at[ind, \"smk_source\"]\n",
    "        if source == \"v7_sheets\": new_date = v7_date\n",
    "        elif source == \"v8_local_url_files\": new_date = v8_date\n",
    "        elif source == \"safari\" or source == \"chrome\": new_date = v9_date\n",
    "        total_2.at[ind, \"date_added\"] = new_date\n",
    "    \n",
    "total_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24906680",
   "metadata": {},
   "source": [
    "<a id=\"seperate_others\"></a>\n",
    "## 6. Seperate AO3 works vs Others (non-ao3 & ao3 external works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get others DF (non-AO3 and ao3 external works)\n",
    "external = total_2.query(\"url.str.contains('archiveofourown.org/external_works/')\")\n",
    "dfOther = total_2.query(\"~url.str.contains('archiveofourown.org/')\")\n",
    "dfOther = pd.concat([external, dfOther]).reset_index(drop=True)\n",
    "\n",
    "dfOther.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161380b",
   "metadata": {},
   "source": [
    "#### Others CHECKPOINT! others-0-all.csv (all non-AO3 urls & AO3 external works from all urls post 1/13/23, inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfOther.to_csv(\"data-checkpoints/others-0-all_01-03-23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0798d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get non-other (aka all ao3) dtb\n",
    "total_3 = total_2.query(\"url.str.contains('archiveofourown.org/')\") \\\n",
    "        .query(\"~url.str.contains('archiveofourown.org/external_works/')\") \\\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "total_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d79e3b",
   "metadata": {},
   "source": [
    "<a id='seperate_ao3_dtbs'></a>\n",
    "## 7. Label ao3 work_type & separate into DTBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e422523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add new columns for id & url_type\n",
    "total_3[\"id\"] = np.nan\n",
    "total_3[\"url_type\"] = np.nan\n",
    "\n",
    "# label all cols\n",
    "for ind in total_3.index:\n",
    "    url = total_3.at[ind, \"url\"]\n",
    "    \n",
    "    data = getTypeAndId(url)\n",
    "    wType = data[0]\n",
    "    wId = data[1]\n",
    "    \n",
    "    total_3.at[ind, \"url_type\"] = wType\n",
    "    total_3.at[ind, \"id\"] = wId\n",
    "\n",
    "total_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize cols order\n",
    "total_3[\"location_found\"] = \"AO3\"\n",
    "all_ao3_links = total_3[[\"dtb_type\",\"location_found\",\"smk_source\",\"version\",\n",
    "                   \"date_added\",\"date_last_viewed\",\"url_type\",\"id\",\"url\"]]\n",
    "# all_ao3_links.to_csv(f\"data-checkpoints/all_ao3_links_until_01-13-23__{cur_date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962ac8c",
   "metadata": {},
   "source": [
    "#### ** All AO3 links including 1-13-23, inclusive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f098b",
   "metadata": {},
   "source": [
    "<a id='clean_7'></a>\n",
    "## 8. Clean up & customize the new 7 databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777958e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ao3_links = pd.read_csv(\"data-checkpoints/all_ao3_links_until_01-13-23__02-26-23.csv\", \n",
    "                            index_col=0,\n",
    "                            parse_dates = ['date_added','date_last_viewed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0246ab",
   "metadata": {},
   "source": [
    "### 8.1) Clean & save Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a7735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate collections from all_ao3_links\n",
    "colDTB = all_ao3_links.query(\"url_type == 'collections'\") \\\n",
    "                .reset_index(drop=True).rename(columns={\"id\":\"name\"}) \\\n",
    "                .drop(columns=[\"url_type\"])\n",
    "\n",
    "# correct data input mistake\n",
    "colDTB.at[0,\"name\"] = \"Canon_Divergence\"\n",
    "\n",
    "# write first col checkpoint\n",
    "colDTB.to_csv(f\"data-checkpoints/col-0-all_{cur_date}.csv\")\n",
    "\n",
    "colDTB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12e6fe",
   "metadata": {},
   "source": [
    "#### ** Collections CHECKPOINT! - \"col-0-all_02-26-23.csv\" (all collections until this point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce295be",
   "metadata": {},
   "source": [
    "### 8.2) Clean & save Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a74636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning searches\n",
    "searchDTB = all_ao3_links.query(\"url_type == 'search'\") \\\n",
    "                .reset_index(drop=True).rename(columns={\"id\":\"search_str\"}) \\\n",
    "                .drop(columns=[\"url_type\"])\n",
    "\n",
    "# write first col checkpoint\n",
    "searchDTB.to_csv(f\"data-checkpoints/search-0-all_{cur_date}.csv\")\n",
    "\n",
    "searchDTB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3618e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning series\n",
    "seriesDTB = all_ao3_links.query(\"url_type == 'series'\") \\\n",
    "                .reset_index(drop=True) \\\n",
    "                .drop(columns=[\"url_type\"])\n",
    "\n",
    "# write first col checkpoint\n",
    "seriesDTB.to_csv(f\"data-checkpoints/series-0-all_{cur_date}.csv\")\n",
    "\n",
    "seriesDTB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a76e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning tags\n",
    "tagsDTB = all_ao3_links.query(\"url_type == 'tags'\") \\\n",
    "                .reset_index(drop=True) \\\n",
    "                .rename(columns={\"id\":\"tag_str\"}) \\\n",
    "                .drop(columns=[\"url_type\"])\n",
    "\n",
    "tagsDTB[\"tag_type\"] = np.nan\n",
    "tagsDTB[\"tag_type\"] = tagsDTB[\"tag_type\"].astype(str)\n",
    "\n",
    "# write first col checkpoint\n",
    "tagsDTB.to_csv(f\"data-checkpoints/tags-0-all_{cur_date}.csv\")\n",
    "\n",
    "tagsDTB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning users\n",
    "usersDTB = all_ao3_links.query(\"url_type == 'users'\") \\\n",
    "                .reset_index(drop=True) \\\n",
    "                .rename(columns={\"id\":\"user_name\"}) \\\n",
    "                .drop(columns=[\"url_type\"])\n",
    "\n",
    "# write first col checkpoint\n",
    "usersDTB.to_csv(f\"data-checkpoints/users-0-all_{cur_date}.csv\")\n",
    "\n",
    "usersDTB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2dd101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cleaning fics\n",
    "ficDTB = all_ao3_links.query(\"url_type == 'chapters' or url_type == 'works' or \\\n",
    "                url_type.str.contains('collections:')\") \\\n",
    "                .reset_index(drop=True) \n",
    "\n",
    "# write first checkpoint\n",
    "ficDTB.to_csv(f\"data-checkpoints/fic-0-all_{cur_date}.csv\")\n",
    "\n",
    "ficDTB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e7afa",
   "metadata": {},
   "source": [
    "#### CHECKPOINT! - 0 (for all: collections, comments, search, tags, users)\n",
    "- stored in data-checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d1257",
   "metadata": {},
   "source": [
    "<a id='fill_series'></a>\n",
    "## 9. Fill seriesDTB (already de-dupped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bedc7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_columns = {'dtb_type', 'location_found', 'smk_source', 'version', 'date_added',\n",
    "       'date_last_viewed', 'id', 'url', 'name', 'creators', 'fandoms',\n",
    "       'series_obj', 'date_obj_updated', 'description', 'notes', 'words',\n",
    "       'complete', 'is_subscribed', 'series_begun', 'series_updated',\n",
    "       'nbookmarks', 'nworks', 'work_list', 'is_restricted', 'not_found'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2dacc9",
   "metadata": {},
   "source": [
    "<a id='fill_series.1'></a>\n",
    "### 9.1 Define Series-filling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "df8d70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import AO3\n",
    "\n",
    "def my_session():\n",
    "    \"\"\"\n",
    "    Returns an AO3 session logged in to my account.\n",
    "    \"\"\"\n",
    "    payload = open(\"randomData/to_add_authors.txt\", \"r\")\n",
    "    user = payload.readline().strip()\n",
    "    password = payload.readline().strip()\n",
    "    \n",
    "    sess = AO3.Session(user, password)\n",
    "    sess.refresh_auth_token()\n",
    "    info.close()\n",
    "    \n",
    "    return sess\n",
    "\n",
    "# AO3.utils.limit_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "107d787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeriesFandoms(series_obj):\n",
    "    \"\"\"\n",
    "    Takes an AO3.Series object.\n",
    "    Returns a list of all fandoms from all works in given series.\n",
    "    \"\"\"\n",
    "    fandoms = []\n",
    "    work_list = get_series_work_list(series_obj)\n",
    "    for work in work_list:\n",
    "        for fandom in work.fandoms:\n",
    "            if fandom not in fandoms:\n",
    "                fandoms.append(fandom)\n",
    "    \n",
    "    return fandoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ee7c6eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_work_list(series_obj):\n",
    "    try: return [work for work in series_obj.work_list]\n",
    "    except UnboundLocalError: return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "ea54d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_row_complete(row):\n",
    "    new_row = row.copy().drop(columns=['dtb_type','date_last_viewed', \n",
    "                                       'description', 'notes'])\n",
    "    return len(np.where(pd.isnull(new_row))[1]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ed95d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_series_ao3_info(series_id, session, report=False):\n",
    "    \"\"\"\n",
    "    Takes a series id (int).\n",
    "    Returns a 1-row pandas DF populated by ao3 data from the given series id.\n",
    "    \"\"\"\n",
    "    # initialize temp holder & Series obj\n",
    "    single_series = pd.DataFrame({'id': [series_id]})\n",
    "    series = AO3.Series(series_id, session=session)\n",
    "\n",
    "    # write report info\n",
    "    name = series.name\n",
    "    creators = json.dumps([user.username for user in series.creators])\n",
    "    fandoms = json.dumps(getSeriesFandoms(series))\n",
    "\n",
    "    single_series['name'] = name\n",
    "    single_series['creators'] = creators\n",
    "    single_series['fandoms'] = fandoms\n",
    "    if report: print(f\"- Wrote '{name}' by {creators}\\nin {fandoms}\")\n",
    "\n",
    "    # write remaining info\n",
    "    single_series['series_obj'] = series\n",
    "    single_series['date_obj_updated'] = datetime.now()\n",
    "    \n",
    "    single_series['description'] = series.description\n",
    "    single_series['notes'] = series.notes\n",
    "    single_series['words'] = series.words\n",
    "    single_series['complete'] = series.complete\n",
    "    single_series['is_subscribed'] = series.is_subscribed\n",
    "    \n",
    "    single_series['series_begun'] = series.series_begun\n",
    "    single_series['series_updated'] = series.series_updated\n",
    "    single_series['nbookmarks'] = series.nbookmarks\n",
    "    single_series['nworks'] = series.nworks\n",
    "    single_series['work_list'] = json.dumps([work.id for work in get_series_work_list(series)])\n",
    "    \n",
    "    single_series['is_restricted'] = series._soup.find(\"img\", {\"title\": \"Restricted\"}) is not None\n",
    "    single_series['not_found'] = False\n",
    "    \n",
    "    return single_series\n",
    "\n",
    "# fill_series_ao3_info(1575793, my_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2fe529bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_series_dtb(initial_series_dtb, session, update=False, report=False):\n",
    "    \"\"\"\n",
    "    Takes boolean (use account/able to access restricted?)\n",
    "    Fills any empty row of initial_series_dtb with: name, creators, fandoms, Series obj, and date this all last updated\n",
    "    Requires that all rows' id be filled in.\n",
    "    Returns nothing. Modifies initial_series_dtb.\n",
    "    \"\"\"\n",
    "    # find total number of series to fill\n",
    "    total = max(initial_series_dtb.index)\n",
    "    \n",
    "    # ensure initial_series_dtb has all necessary columns\n",
    "    for col in series_columns:\n",
    "        if col not in initial_series_dtb.columns:\n",
    "            initial_series_dtb[col] = np.nan\n",
    "\n",
    "    # fill all series/rows in initial_series_dtb\n",
    "    for ind in initial_series_dtb.index: \n",
    "        try: \n",
    "            # when not using full-report, alert at every 100 series\n",
    "            if not report:\n",
    "                if ind%100 == 0: \n",
    "                    print(f'- {ind}! (printed every 100)')\n",
    "            \n",
    "            # if series/row not entirely filled in OR we're updating the dtb \n",
    "            if (not series_row_complete(initial_series_dtb.iloc[[ind]])) or update: \n",
    "                # get series id\n",
    "                series_id = initial_series_dtb.at[ind, \"id\"]\n",
    "                if report: print(f\"{ind}: [{(ind/total)*100:.2f}%] Filling for [{series_id}]\")\n",
    "                \n",
    "                # get ao3 info\n",
    "                series_ao3_info = fill_series_ao3_info(series_id, session, report=report)\n",
    "                \n",
    "                # update initial_series_dtb with series_ao3_info (new info will overwrite old info)\n",
    "                series_ao3_info.index = [ind]\n",
    "                initial_series_dtb.update(series_ao3_info, join='left', overwrite=True)\n",
    "            \n",
    "            # if series/row is satifactory\n",
    "            else: \n",
    "                if report: print(f\"{ind}: .\")\n",
    "        \n",
    "        # if something goes wrong \n",
    "        except Exception as e:\n",
    "            initial_series_dtb.at[ind, \"not_found\"] = True\n",
    "            print(f\"-- ERROR, {ind}: {initial_series_dtb.at[ind, 'id']}\")\n",
    "        \n",
    "        # update temp csv w/ new row/series\n",
    "        initial_series_dtb.to_csv(\"temp_series.csv\")\n",
    "\n",
    "    # Write finished series DTB to csv\n",
    "    initial_series_dtb.to_csv(\"temp_series_final.csv\")\n",
    "\n",
    "    print(\"\\nDONE!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2c8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "87bb974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_series_dtb_original(initial_series_dtb, session, report=False):\n",
    "    \"\"\"\n",
    "    Takes boolean (use account/able to access restricted?)\n",
    "    Fills any empty row of initial_series_dtb with: name, creators, fandoms, Series obj, and date this all last updated\n",
    "    Requires that all rows' id be filled in.\n",
    "    Returns nothing. Modifies initial_series_dtb.\n",
    "    \"\"\"\n",
    "    # find total number of series to fill\n",
    "    total = max(initial_series_dtb.index)\n",
    "    \n",
    "    # ensure initial_series_dtb has all necessary columns\n",
    "    for col in series_columns:\n",
    "        if col not in initial_series_dtb.columns:\n",
    "            initial_series_dtb[col] = np.nan\n",
    "\n",
    "    for ind in initial_series_dtb.index: # for every row in initial_series_dtb\n",
    "        try: \n",
    "            if not report:\n",
    "                if ind%100 == 0: \n",
    "                    print(f'- {ind}! (printed every 100)')\n",
    "\n",
    "            if not series_row_complete(initial_series_dtb.iloc[[ind]]): # if any null value in rows (sans last_viewed & is_subbed)\n",
    "                # get series id\n",
    "                series_id = initial_series_dtb.at[ind, \"id\"]\n",
    "                if report: print(f\"{ind}: [{(ind/total)*100:.2f}%] Filling for [{series_id}]\")\n",
    "\n",
    "                # initialize Series obj\n",
    "                series = AO3.Series(series_id, session=session)\n",
    "\n",
    "                # write report info\n",
    "                name = series.name\n",
    "                creators = json.dumps([user.username for user in series.creators])\n",
    "                fandoms = json.dumps(getSeriesFandoms(series))\n",
    "\n",
    "                initial_series_dtb.at[ind, \"name\"] = name\n",
    "                initial_series_dtb.at[ind, \"creators\"] = creators\n",
    "                initial_series_dtb.at[ind, \"fandoms\"] = fandoms\n",
    "                if report: print(f\"- Wrote '{name}' by {creators}\\nin {fandoms}\")\n",
    "\n",
    "                # write remaining info\n",
    "                initial_series_dtb.at[ind, \"series_obj\"] = series\n",
    "                initial_series_dtb.at[ind, \"date_obj_updated\"] = datetime.now()\n",
    "\n",
    "                initial_series_dtb.at[ind, \"description\"] = series.description\n",
    "                initial_series_dtb.at[ind, \"notes\"] = series.notes\n",
    "                initial_series_dtb.at[ind, \"words\"] = series.words\n",
    "                initial_series_dtb.at[ind, \"complete\"] = series.complete\n",
    "                initial_series_dtb.at[ind, \"is_subscribed\"] = series.is_subscribed\n",
    "\n",
    "                initial_series_dtb.at[ind, \"series_begun\"] = series.series_begun\n",
    "                initial_series_dtb.at[ind, \"series_updated\"] = series.series_updated\n",
    "                initial_series_dtb.at[ind, \"nbookmarks\"] = series.nbookmarks\n",
    "                initial_series_dtb.at[ind, \"nworks\"] = series.nworks\n",
    "                initial_series_dtb.at[ind, \"work_list\"] = json.dumps([work.id for work in get_series_work_list(series)])\n",
    "\n",
    "                initial_series_dtb.at[ind, \"is_restricted\"] = series._soup.find(\"img\", {\"title\": \"Restricted\"}) is not None\n",
    "                initial_series_dtb.at[ind, \"not_found\"] = False\n",
    "            else: \n",
    "                if report: print(f\"{ind}: .\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            initial_series_dtb.at[ind, \"not_found\"] = True\n",
    "            print(f\"-- ERROR, {ind}: {initial_series_dtb.at[ind, 'id']}\")\n",
    "        \n",
    "        # update temp csv w/ new row/series\n",
    "        initial_series_dtb.to_csv(\"temp_series.csv\")\n",
    "\n",
    "    # Write finished series DTB to csv\n",
    "    initial_series_dtb.to_csv(\"temp_series_final.csv\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nDONE!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cdd5e6",
   "metadata": {},
   "source": [
    "<a id='fill_series.2'></a>\n",
    "### 9.2 Fill SeriesDTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "186202ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most recent series data\n",
    "seriesDTB = pd.read_csv(\"data-checkpoints/series-0-all_02-26-23.csv\", \n",
    "                        index_col=0,\n",
    "                        parse_dates=['date_added', 'date_last_viewed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3bc6c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = my_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "2bfa94ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fill_series_dtb_original' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [377]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfill_series_dtb_original\u001b[49m(seriesDTB, ss1, report\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fill_series_dtb_original' is not defined"
     ]
    }
   ],
   "source": [
    "fill_series_dtb_original(seriesDTB, ss1, report=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "cce46312",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = fill_series_ao3_info(1575793, ss1)\n",
    "r2 = fill_series_ao3_info(1021446, ss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "7db0162b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "57e8d023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtb_type</th>\n",
       "      <th>location_found</th>\n",
       "      <th>smk_source</th>\n",
       "      <th>version</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_last_viewed</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>creators</th>\n",
       "      <th>fandoms</th>\n",
       "      <th>series_obj</th>\n",
       "      <th>date_obj_updated</th>\n",
       "      <th>description</th>\n",
       "      <th>notes</th>\n",
       "      <th>words</th>\n",
       "      <th>complete</th>\n",
       "      <th>is_subscribed</th>\n",
       "      <th>series_begun</th>\n",
       "      <th>series_updated</th>\n",
       "      <th>nbookmarks</th>\n",
       "      <th>nworks</th>\n",
       "      <th>work_list</th>\n",
       "      <th>is_restricted</th>\n",
       "      <th>not_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1575793.0</td>\n",
       "      <td>http://www.archiveofourown.org/series/1575793</td>\n",
       "      <td>Shutterbug</td>\n",
       "      <td>[\"goldkirk\"]</td>\n",
       "      <td>[\"Batman - All Media Types\", \"Batman (Comics)\"...</td>\n",
       "      <td>&lt;Series [Shutterbug]&gt;</td>\n",
       "      <td>2023-03-07 12:01:09.472361</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>352956.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[21672928, 21947281, 22004809, 34220017, 23990...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1021446.0</td>\n",
       "      <td>https://archiveofourown.org/series/1021446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-09-01 22:13:15</td>\n",
       "      <td>2021-11-09 17:08:02</td>\n",
       "      <td>1029669.0</td>\n",
       "      <td>https://archiveofourown.org/series/1029669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to_read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1052768.0</td>\n",
       "      <td>https://archiveofourown.org/series/1052768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1070466.0</td>\n",
       "      <td>https://archiveofourown.org/series/1070466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-04-30 18:01:23</td>\n",
       "      <td>2021-05-02 09:27:26</td>\n",
       "      <td>1304555.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/1304555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>297530.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/297530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>44780.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/44780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>64975.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/64975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>911790.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/911790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dtb_type location_found smk_source  version          date_added  \\\n",
       "0    to_read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "1       read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "2        NaN            AO3  v7_sheets        7 2021-09-01 22:13:15   \n",
       "3    to_read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "4       read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "..       ...            ...        ...      ...                 ...   \n",
       "172      NaN            AO3  v7_sheets        7 2021-04-30 18:01:23   \n",
       "173     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "174     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "175     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "176     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "\n",
       "       date_last_viewed         id  \\\n",
       "0                   NaT  1575793.0   \n",
       "1                   NaT  1021446.0   \n",
       "2   2021-11-09 17:08:02  1029669.0   \n",
       "3                   NaT  1052768.0   \n",
       "4                   NaT  1070466.0   \n",
       "..                  ...        ...   \n",
       "172 2021-05-02 09:27:26  1304555.0   \n",
       "173                 NaT   297530.0   \n",
       "174                 NaT    44780.0   \n",
       "175                 NaT    64975.0   \n",
       "176                 NaT   911790.0   \n",
       "\n",
       "                                                url        name      creators  \\\n",
       "0     http://www.archiveofourown.org/series/1575793  Shutterbug  [\"goldkirk\"]   \n",
       "1        https://archiveofourown.org/series/1021446         NaN           NaN   \n",
       "2        https://archiveofourown.org/series/1029669         NaN           NaN   \n",
       "3        https://archiveofourown.org/series/1052768         NaN           NaN   \n",
       "4        https://archiveofourown.org/series/1070466         NaN           NaN   \n",
       "..                                              ...         ...           ...   \n",
       "172  https://www.archiveofourown.org/series/1304555         NaN           NaN   \n",
       "173   https://www.archiveofourown.org/series/297530         NaN           NaN   \n",
       "174    https://www.archiveofourown.org/series/44780         NaN           NaN   \n",
       "175    https://www.archiveofourown.org/series/64975         NaN           NaN   \n",
       "176   https://www.archiveofourown.org/series/911790         NaN           NaN   \n",
       "\n",
       "                                               fandoms             series_obj  \\\n",
       "0    [\"Batman - All Media Types\", \"Batman (Comics)\"...  <Series [Shutterbug]>   \n",
       "1                                                  NaN                    NaN   \n",
       "2                                                  NaN                    NaN   \n",
       "3                                                  NaN                    NaN   \n",
       "4                                                  NaN                    NaN   \n",
       "..                                                 ...                    ...   \n",
       "172                                                NaN                    NaN   \n",
       "173                                                NaN                    NaN   \n",
       "174                                                NaN                    NaN   \n",
       "175                                                NaN                    NaN   \n",
       "176                                                NaN                    NaN   \n",
       "\n",
       "              date_obj_updated description notes     words complete  \\\n",
       "0   2023-03-07 12:01:09.472361                    352956.0    False   \n",
       "1                          NaT         NaN   NaN       NaN      NaN   \n",
       "2                          NaT         NaN   NaN       NaN      NaN   \n",
       "3                          NaT         NaN   NaN       NaN      NaN   \n",
       "4                          NaT         NaN   NaN       NaN      NaN   \n",
       "..                         ...         ...   ...       ...      ...   \n",
       "172                        NaT         NaN   NaN       NaN      NaN   \n",
       "173                        NaT         NaN   NaN       NaN      NaN   \n",
       "174                        NaT         NaN   NaN       NaN      NaN   \n",
       "175                        NaT         NaN   NaN       NaN      NaN   \n",
       "176                        NaT         NaN   NaN       NaN      NaN   \n",
       "\n",
       "    is_subscribed series_begun series_updated  nbookmarks  nworks  \\\n",
       "0            True   2019-12-04     2022-12-29      1823.0     9.0   \n",
       "1             NaN          NaN            NaN         NaN     NaN   \n",
       "2             NaN          NaN            NaN         NaN     NaN   \n",
       "3             NaN          NaN            NaN         NaN     NaN   \n",
       "4             NaN          NaN            NaN         NaN     NaN   \n",
       "..            ...          ...            ...         ...     ...   \n",
       "172           NaN          NaN            NaN         NaN     NaN   \n",
       "173           NaN          NaN            NaN         NaN     NaN   \n",
       "174           NaN          NaN            NaN         NaN     NaN   \n",
       "175           NaN          NaN            NaN         NaN     NaN   \n",
       "176           NaN          NaN            NaN         NaN     NaN   \n",
       "\n",
       "                                             work_list is_restricted not_found  \n",
       "0    [21672928, 21947281, 22004809, 34220017, 23990...         False     False  \n",
       "1                                                  NaN           NaN       NaN  \n",
       "2                                                  NaN           NaN       NaN  \n",
       "3                                                  NaN           NaN       NaN  \n",
       "4                                                  NaN           NaN       NaN  \n",
       "..                                                 ...           ...       ...  \n",
       "172                                                NaN           NaN       NaN  \n",
       "173                                                NaN           NaN       NaN  \n",
       "174                                                NaN           NaN       NaN  \n",
       "175                                                NaN           NaN       NaN  \n",
       "176                                                NaN           NaN       NaN  \n",
       "\n",
       "[177 rows x 25 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.index = [0]\n",
    "test1 = seriesDTB.merge(r1, how='left')\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6e12f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.index = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e4866a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtb_type</th>\n",
       "      <th>location_found</th>\n",
       "      <th>smk_source</th>\n",
       "      <th>version</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_last_viewed</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>creators</th>\n",
       "      <th>fandoms</th>\n",
       "      <th>series_obj</th>\n",
       "      <th>date_obj_updated</th>\n",
       "      <th>description</th>\n",
       "      <th>notes</th>\n",
       "      <th>words</th>\n",
       "      <th>complete</th>\n",
       "      <th>is_subscribed</th>\n",
       "      <th>series_begun</th>\n",
       "      <th>series_updated</th>\n",
       "      <th>nbookmarks</th>\n",
       "      <th>nworks</th>\n",
       "      <th>work_list</th>\n",
       "      <th>is_restricted</th>\n",
       "      <th>not_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1575793.0</td>\n",
       "      <td>http://www.archiveofourown.org/series/1575793</td>\n",
       "      <td>Shutterbug</td>\n",
       "      <td>[\"goldkirk\"]</td>\n",
       "      <td>[\"Batman - All Media Types\", \"Batman (Comics)\"...</td>\n",
       "      <td>&lt;Series [Shutterbug]&gt;</td>\n",
       "      <td>2023-03-07 12:01:09.472361</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>352956.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-12-04</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>[21672928, 21947281, 22004809, 34220017, 23990...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1021446.0</td>\n",
       "      <td>https://archiveofourown.org/series/1021446</td>\n",
       "      <td>Bait and Switch 'verse</td>\n",
       "      <td>[\"galwednesday\"]</td>\n",
       "      <td>[\"The Avengers (Marvel Movies)\", \"Captain Amer...</td>\n",
       "      <td>&lt;Series [Bait and Switch 'verse]&gt;</td>\n",
       "      <td>2023-03-07 12:01:09.911304</td>\n",
       "      <td>(This is marked as complete to show there are ...</td>\n",
       "      <td></td>\n",
       "      <td>5797.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>842.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[13554312, 14626809, 22515736]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-09-01 22:13:15</td>\n",
       "      <td>2021-11-09 17:08:02</td>\n",
       "      <td>1029669.0</td>\n",
       "      <td>https://archiveofourown.org/series/1029669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to_read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1052768.0</td>\n",
       "      <td>https://archiveofourown.org/series/1052768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1070466.0</td>\n",
       "      <td>https://archiveofourown.org/series/1070466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-04-30 18:01:23</td>\n",
       "      <td>2021-05-02 09:27:26</td>\n",
       "      <td>1304555.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/1304555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>297530.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/297530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>44780.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/44780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>64975.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/64975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>read</td>\n",
       "      <td>AO3</td>\n",
       "      <td>v7_sheets</td>\n",
       "      <td>7</td>\n",
       "      <td>2022-01-01 00:00:01</td>\n",
       "      <td>NaT</td>\n",
       "      <td>911790.0</td>\n",
       "      <td>https://www.archiveofourown.org/series/911790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dtb_type location_found smk_source  version          date_added  \\\n",
       "0    to_read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "1       read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "2        NaN            AO3  v7_sheets        7 2021-09-01 22:13:15   \n",
       "3    to_read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "4       read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "..       ...            ...        ...      ...                 ...   \n",
       "172      NaN            AO3  v7_sheets        7 2021-04-30 18:01:23   \n",
       "173     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "174     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "175     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "176     read            AO3  v7_sheets        7 2022-01-01 00:00:01   \n",
       "\n",
       "       date_last_viewed         id  \\\n",
       "0                   NaT  1575793.0   \n",
       "1                   NaT  1021446.0   \n",
       "2   2021-11-09 17:08:02  1029669.0   \n",
       "3                   NaT  1052768.0   \n",
       "4                   NaT  1070466.0   \n",
       "..                  ...        ...   \n",
       "172 2021-05-02 09:27:26  1304555.0   \n",
       "173                 NaT   297530.0   \n",
       "174                 NaT    44780.0   \n",
       "175                 NaT    64975.0   \n",
       "176                 NaT   911790.0   \n",
       "\n",
       "                                                url                    name  \\\n",
       "0     http://www.archiveofourown.org/series/1575793              Shutterbug   \n",
       "1        https://archiveofourown.org/series/1021446  Bait and Switch 'verse   \n",
       "2        https://archiveofourown.org/series/1029669                     NaN   \n",
       "3        https://archiveofourown.org/series/1052768                     NaN   \n",
       "4        https://archiveofourown.org/series/1070466                     NaN   \n",
       "..                                              ...                     ...   \n",
       "172  https://www.archiveofourown.org/series/1304555                     NaN   \n",
       "173   https://www.archiveofourown.org/series/297530                     NaN   \n",
       "174    https://www.archiveofourown.org/series/44780                     NaN   \n",
       "175    https://www.archiveofourown.org/series/64975                     NaN   \n",
       "176   https://www.archiveofourown.org/series/911790                     NaN   \n",
       "\n",
       "             creators                                            fandoms  \\\n",
       "0        [\"goldkirk\"]  [\"Batman - All Media Types\", \"Batman (Comics)\"...   \n",
       "1    [\"galwednesday\"]  [\"The Avengers (Marvel Movies)\", \"Captain Amer...   \n",
       "2                 NaN                                                NaN   \n",
       "3                 NaN                                                NaN   \n",
       "4                 NaN                                                NaN   \n",
       "..                ...                                                ...   \n",
       "172               NaN                                                NaN   \n",
       "173               NaN                                                NaN   \n",
       "174               NaN                                                NaN   \n",
       "175               NaN                                                NaN   \n",
       "176               NaN                                                NaN   \n",
       "\n",
       "                            series_obj           date_obj_updated  \\\n",
       "0                <Series [Shutterbug]> 2023-03-07 12:01:09.472361   \n",
       "1    <Series [Bait and Switch 'verse]> 2023-03-07 12:01:09.911304   \n",
       "2                                  NaN                        NaT   \n",
       "3                                  NaN                        NaT   \n",
       "4                                  NaN                        NaT   \n",
       "..                                 ...                        ...   \n",
       "172                                NaN                        NaT   \n",
       "173                                NaN                        NaT   \n",
       "174                                NaN                        NaT   \n",
       "175                                NaN                        NaT   \n",
       "176                                NaN                        NaT   \n",
       "\n",
       "                                           description notes     words  \\\n",
       "0                                                             352956.0   \n",
       "1    (This is marked as complete to show there are ...          5797.0   \n",
       "2                                                  NaN   NaN       NaN   \n",
       "3                                                  NaN   NaN       NaN   \n",
       "4                                                  NaN   NaN       NaN   \n",
       "..                                                 ...   ...       ...   \n",
       "172                                                NaN   NaN       NaN   \n",
       "173                                                NaN   NaN       NaN   \n",
       "174                                                NaN   NaN       NaN   \n",
       "175                                                NaN   NaN       NaN   \n",
       "176                                                NaN   NaN       NaN   \n",
       "\n",
       "    complete is_subscribed series_begun series_updated  nbookmarks  nworks  \\\n",
       "0      False          True   2019-12-04     2022-12-29      1823.0     9.0   \n",
       "1       True         False   2018-02-02     2020-02-02       842.0     3.0   \n",
       "2        NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "3        NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "4        NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "..       ...           ...          ...            ...         ...     ...   \n",
       "172      NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "173      NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "174      NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "175      NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "176      NaN           NaN          NaN            NaN         NaN     NaN   \n",
       "\n",
       "                                             work_list is_restricted not_found  \n",
       "0    [21672928, 21947281, 22004809, 34220017, 23990...         False     False  \n",
       "1                       [13554312, 14626809, 22515736]         False     False  \n",
       "2                                                  NaN           NaN       NaN  \n",
       "3                                                  NaN           NaN       NaN  \n",
       "4                                                  NaN           NaN       NaN  \n",
       "..                                                 ...           ...       ...  \n",
       "172                                                NaN           NaN       NaN  \n",
       "173                                                NaN           NaN       NaN  \n",
       "174                                                NaN           NaN       NaN  \n",
       "175                                                NaN           NaN       NaN  \n",
       "176                                                NaN           NaN       NaN  \n",
       "\n",
       "[177 rows x 25 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.index = [1]\n",
    "test1.update(r2, join='left', overwrite=True)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "f7fea58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inititalize variables\n",
    "sess = my_session()\n",
    "initial_series_dtb = seriesDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f34e24",
   "metadata": {},
   "source": [
    "#### Series CHECKPOINT! (series-1, all & clean) (saved csv files in data-checkpoints)\n",
    "- most recent: 03-06-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63a837",
   "metadata": {},
   "source": [
    "<a id='fill_fics'></a>\n",
    "## 10. Clean & prepare ficDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee893f7",
   "metadata": {},
   "source": [
    "<a id='fill_fics_1'></a>\n",
    "### 10.1 Clean prev data in ficDTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add empty info cols\n",
    "if False: \n",
    "    ficDTB[\"title\"] = np.nan\n",
    "    ficDTB[\"authors\"] = np.nan\n",
    "    ficDTB[\"fandoms\"] = np.nan\n",
    "    \n",
    "    ficDTB[\"fic_obj\"] = np.nan\n",
    "    ficDTB[\"date_obj_updated\"] = np.nan\n",
    "    ficDTB[\"date_obj_updated\"] = pd.to_datetime(ficDTB[\"date_obj_updated\"])\n",
    "    \n",
    "    ficDTB[\"url_pseuds\"] = np.nan\n",
    "    ficDTB[\"col_work\"] = np.nan\n",
    "\n",
    "ficDTB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add col_work collections\n",
    "def getCol(x):\n",
    "    if not \"collections:\" in x: return np.nan\n",
    "    else:\n",
    "        col = x.replace(\"collections:\",\"\")\n",
    "        return col\n",
    "\n",
    "# ficDTB[\"col_work\"] = ficDTB[\"url_type\"].apply(getCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update url_types (aka all 'collections:' -> col_work)\n",
    "def x(x):\n",
    "    if not \"collections:\" in x: return x\n",
    "    else: return \"col_work\"\n",
    "\n",
    "# ficDTB[\"url_type\"] = ficDTB[\"url_type\"].apply(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb142e1",
   "metadata": {},
   "source": [
    "#### Fic CHECKPOINT! (fic-1, all & clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ca8dd",
   "metadata": {},
   "source": [
    "<a id='fill_fics_2'></a>\n",
    "### 10.2 De-dup ficDTB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93d36f",
   "metadata": {},
   "source": [
    "#### ficDTB Columns\n",
    "- dtb_type: (read, to_read/NaN)\n",
    "    - read\n",
    "    - to_read\n",
    "    - NaN\n",
    "- smk_source: (v7, v8, safari, chrome)\n",
    "    - v7_sheets\n",
    "    - v8_local_url_files\n",
    "    - chrome\n",
    "    - safari\n",
    "- version: 7-9 (earliest)\n",
    "- date_added: (earliest)\n",
    "    - date\n",
    "    - NaT\n",
    "- date_last_viewed (latest)\n",
    "    - date\n",
    "    - NaT\n",
    "- url_type (works) (add others to url_psueds)\n",
    "    - works\n",
    "    - col_work\n",
    "    - chapters\n",
    "- id: num\n",
    "- url: url\n",
    "- col_work: list of col names\n",
    "- url_psueds: list of non-main urls\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f04f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in ficDTB from checkpoint\n",
    "ficDups = pd.read_csv(\"data-checkpoints/fic-1-clean_01-17-23_11-42-48.csv\", index_col=0, \n",
    "                      parse_dates=[\"date_added\",\"date_last_viewed\"])\n",
    "ficDups[\"url_psueds\"] = json.dumps([])\n",
    "ficDups.head() # fic_obj col no longer holds functional Fic objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5212667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectInfo(dtbCol, orderList):\n",
    "    infos = wSlice[dtbCol].to_list()\n",
    "    temp_info = np.nan\n",
    "    for info in orderList:\n",
    "        if info in infos: \n",
    "            temp_info = info\n",
    "            break\n",
    "            \n",
    "    return temp_info\n",
    "\n",
    "# all_smk_sources = [\"v7_sheets\",\"v8_local_url_files\",\"safari\",\"chrome\"]\n",
    "# selectInfo(\"smk_source\", all_smk_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ea4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyFicDTB():\n",
    "    # initialize res\n",
    "    res = pd.DataFrame(columns=['dtb_type',\n",
    "                                 'smk_source',\n",
    "                                 'version',\n",
    "                                 'date_added',\n",
    "                                 'date_last_viewed',\n",
    "                                 'url_type',\n",
    "                                 'id',\n",
    "                                 'url',\n",
    "                                 'col_work',\n",
    "                                 'url_psueds'])\n",
    "    \n",
    "    # make right dtypes\n",
    "    res[\"version\"] = res[\"version\"].astype(\"int\")\n",
    "    res[\"id\"] = res[\"id\"].astype(\"int\")\n",
    "    \n",
    "    res[\"date_added\"] = pd.to_datetime(res[\"date_added\"])\n",
    "    res[\"date_last_viewed\"] = pd.to_datetime(res[\"date_last_viewed\"])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e6b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mergeFics(ficId, ficDups):\n",
    "    \"\"\"\n",
    "    Takes AO3 fic id, finds all fics with the same id in ficDups, merges them into one row.\n",
    "    May need to update row all-value lists\n",
    "    Returns that single row.\n",
    "    \"\"\"\n",
    "    # get rows with same fic id\n",
    "    wSlice = ficDups[ficDups[\"id\"] == ficId].copy()\n",
    "    # print(wSlice)\n",
    "    \n",
    "    if len(temp) > 1:\n",
    "        # initialize temp result DF\n",
    "        res = emptyFicDTB()\n",
    "\n",
    "        # write dtb_type\n",
    "        res.at[0,\"dtb_type\"] = selectInfo(\"dtb_type\", all_dtb_types)\n",
    "\n",
    "        # write smk_source\n",
    "        res.at[0,\"smk_source\"] = selectInfo(\"smk_source\", all_smk_sources)\n",
    "\n",
    "        # write version\n",
    "        res.at[0,\"version\"] = min(wSlice[\"version\"].to_list())\n",
    "\n",
    "        # write date_added\n",
    "        res.at[0,\"date_added\"] = min(wSlice[\"date_added\"].to_list())\n",
    "\n",
    "        # write date_last_viewed\n",
    "        res.at[0,\"date_last_viewed\"] = max(wSlice[\"date_last_viewed\"].to_list())\n",
    "\n",
    "        # write id\n",
    "        res.at[0,\"id\"] = ficId\n",
    "\n",
    "        # write col_work\n",
    "        res.at[0,\"col_work\"] = json.dumps([x for x in wSlice[\"col_work\"].to_list() if not pd.isnull(x)])\n",
    "\n",
    "        # write url\n",
    "        url = wSlice.iloc[0][\"url\"]\n",
    "        res.at[0,\"url\"] = url\n",
    "\n",
    "        # write url_type\n",
    "        wType = getTypeAndId(url)[0]\n",
    "        if \"collections:\" in wType: wType = \"col_work\"\n",
    "        res.at[0,\"url_type\"] = wType\n",
    "        \n",
    "        # write url_psueds\n",
    "        psueds = wSlice.url.drop_duplicates().to_list()[1:]\n",
    "        if psueds is None: psueds = []\n",
    "        res.at[0,\"url_psueds\"] = json.dumps(psueds)\n",
    "        \n",
    "    else:\n",
    "        res = wSlice.iloc[0]\n",
    "    \n",
    "    return res\n",
    "        \n",
    "# mergeFics(19413088, ficDups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c02a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deDupFics(ficDTB):\n",
    "    \"\"\"\n",
    "    Takes a ficDTB, de-dups all fics in a way that preserves desired fic info order. Prints a progress bar.\n",
    "    Returns a ficDTB with no duplicate fics & data preserved.\n",
    "    \"\"\"\n",
    "    # fic info order (for dtb_types & sml_sources)\n",
    "    all_dtb_types = [\"read\",\"to_read\"]\n",
    "    all_smk_sources = [\"v7_sheets\",\"v8_local_url_files\",\"safari\",\"chrome\"]\n",
    "    \n",
    "    # make temp holder & get all ids\n",
    "    temp_ficDTB = emptyFicDTB()\n",
    "    ids = ficDTB.id.drop_duplicates().to_list()\n",
    "    total = len(ids)\n",
    "    \n",
    "    # print report\n",
    "    print(f\"TOTAL: {total} ids to de-dup! {(total//100+1)*'|'}\")\n",
    "    print(f\"{len(str(total))*' '}              PROGESS: \",end='')\n",
    "    \n",
    "    # add newly merged fics\n",
    "    for i, wId in enumerate(ids):\n",
    "        temp_row = mergeFics(wId, ficDTB)\n",
    "        temp_ficDTB = pd.concat([temp_ficDTB, temp_row])\n",
    "        \n",
    "        # progress bar\n",
    "        if (i%100) == 0: print('|', end=\"\")\n",
    "\n",
    "    return temp_ficDTB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-dup ficDTB\n",
    "ficDups = pd.read_csv(\"data-checkpoints/fic-1-clean_01-17-23_11-42-48.csv\", index_col=0, \n",
    "                      parse_dates=[\"date_added\",\"date_last_viewed\"])\n",
    "ficDups[\"version\"] = ficDups[\"version\"].astype(\"int\")\n",
    "ficDups[\"id\"] = ficDups[\"id\"].astype(\"int\")\n",
    "\n",
    "ficNoDups = deDupFics(ficDups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write checkpoint\n",
    "ficNoDups[\"version\"] = ficNoDups[\"version\"].astype(\"int\")\n",
    "ficNoDups[\"id\"] = ficNoDups[\"id\"].astype(\"int\")\n",
    "\n",
    "# ficNoDups.to_csv(\"data-checkpoints/fic-2-all_01-18-23.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b49e94",
   "metadata": {},
   "source": [
    "#### Fic CHECKPOINT! (fic-2, all & fic de-dupped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb492e08",
   "metadata": {},
   "source": [
    "<a id='fill_fics_3'></a>\n",
    "### 10.3 Prepare ficDTB to be filled by AO3 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe686803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in checkpoint\n",
    "ficDTB = pd.read_csv(\"data-checkpoints/fic-2-all_01-18-23.csv\", index_col=0,\n",
    "                     parse_dates=[\"date_added\",\"date_last_viewed\"]) \\\n",
    "                    .reset_index(drop=True) \\\n",
    "                    .drop(columns=['cur_chapter','notes'])\n",
    "ficDTB.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a822d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all col_name groups\n",
    "cols = ['location_found','is_missing',\n",
    "        'dtb_type','smk_source','version','date_added','date_last_viewed','url_type','id','url',\n",
    "        'recced_from_collections','url_psueds']\n",
    "\n",
    "tags = ['title','authors','fandoms','rating','categories','warnings',\n",
    "        'relationships','characters','tags','series','collections']\n",
    "\n",
    "meta = ['words','nchapters','expected_chapters', 'complete',\n",
    "        'date_published','date_updated','date_edited',\n",
    "        'language','restricted','metadata',]\n",
    "\n",
    "text = ['summary','start_notes','end_notes','chapters','text',]\n",
    "\n",
    "stats = ['kudos','comments','bookmarks','hits',]\n",
    "\n",
    "\n",
    "tags.extend(meta)\n",
    "tags.extend(text)\n",
    "tags.extend(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cols to be used\n",
    "if True: \n",
    "    for col in tags:\n",
    "        ficDTB[col] = np.nan\n",
    "        \n",
    "    man_tags = ['fic_obj','date_obj_updated','is_subscribed','cur_chapter','notes']\n",
    "    for tag in man_tags:\n",
    "        ficDTB[tag] = np.nan\n",
    "        \n",
    "    ficDTB[\"location_found\"] = 'AO3'\n",
    "    ficDTB[\"is_missing\"] = np.nan\n",
    "    \n",
    "    ficDTB = ficDTB.rename(columns={\"col_work\":\"recced_from_collections\"})\n",
    "\n",
    "    ficDTB[\"date_obj_updated\"] = pd.to_datetime(ficDTB[\"date_obj_updated\"])\n",
    "    ficDTB[\"date_published\"] = pd.to_datetime(ficDTB[\"date_published\"])\n",
    "    ficDTB[\"date_updated\"] = pd.to_datetime(ficDTB[\"date_updated\"])\n",
    "    ficDTB[\"date_edited\"] = pd.to_datetime(ficDTB[\"date_edited\"])\n",
    "\n",
    "# reorganize new & old cols into desired order\n",
    "all_cols = cols + man_tags + tags\n",
    "ficDTB = ficDTB[all_cols]\n",
    "\n",
    "ficDTB.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200b08d",
   "metadata": {},
   "source": [
    "#### Fic CHECKPOINT! (fic-3-all, all data from prev versions + empty cols ready to be filled by AO3 API)\n",
    "- most recent02-03-23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03022af9",
   "metadata": {},
   "source": [
    "# And the notebook is done here!\n",
    "- Next notebook is focused on competely compiling ALL fics into ficDTB & filling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c31319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
